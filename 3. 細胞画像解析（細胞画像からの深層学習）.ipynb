{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 細胞画像から細胞状態を直接予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今までは、細胞の大きさなどを観測した後に、芽の大きさで細胞周期を分けることを考えていましたが、ここでは、画像から直接細胞状態を推定する予測器を作成します。手間のかかる特徴量の抽出を無くせるという利点がある一方で、どの特徴が重要で分類できたのかは分かりにくくなるので、目的によって、適切に使い分けてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深層学習のサンプルとして、数字のMNIST、画像のImageNetなどの定形データに対する解析方法は、いずれの深層学習フレームワークでもドキュメントに書かれていますが、データ形式が少し変化したりすると、とたんにドキュメントが少なくなる現状のため、この講義では、生命科学ではよくあるだろうシチュエーションのデータ形式を考えつつ、サンプルを用意します。難解だとおもったら、PyTorchのチュートリアルなどを見て、再度このドキュメント・プログラムを見てもらえればと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2節同様に、利用するライブラリ一群を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量から読み込んだ事例では、学習開始前に全てのデータを読み込み、学習時には、そこからバッチ毎にデータを読み込んでいました。画像の場合も同様ですが、ここでは、大規模データに対応できる工夫を導入します。\n",
    "\n",
    "画像や動画の場合には、枚数が多くなるとメモリに乗らない分量の大規模なデータになることがあります。このような場合には、学習前に全てのデータを読み込むことはできません。そこで、学習前にはファイル名（あるいは、ファイル名を知るために必要な値）だけを読み込み、バッチ毎に、バッチ内にあるサンプルの画像や動画を読み込みます。これにより、バッチ対象となるデータが読み込みさえすれば、学習を進めることができるので、全データ分のメモリが用意できなくても学習が可能です。\n",
    "\n",
    "さらに、このバッチごとの読み込みには複数の利点があります。\n",
    "\n",
    "* 深層学習では、高速化のためCPUではなくGPUを利用した計算が行われますが、GPUの欠点として、メモリが少ないことが挙げられます。たとえば、現在よく使われるNVIDIA社のGTX1080で8GB、サーバ用途で利用されるNVIDIA社のTESLA V100で16GB〜32GBと、CPUから利用できるメモリに比べると少々少なくなっています。バッチごとのデータ読み込みが可能になることで、メモリ量が限られた環境でも、効率良い学習が可能になります。\n",
    "* データの擬似的な拡張(水増し：Augmentation)との相性が良いです。例えば、画像解析を考えた場合に、上下左右の反転をしたり、回転をしても、同一のクラスとして認識して欲しい場合が多くあります（カメラを傾けても、ネコはネコなので）。この場合、画像を適当な角度で回転して、学習しても構わないことになります。予め、様々な角度の画像を用意しておくことも、一つの作戦ですが、ただでさえ枚数が多い画像が更に多くなって、ハードディスク容量の圧迫に繋がる可能性があります。そこで、バッチ毎に画像を読み込む際に、乱数を発生させて、適当な角度に回転したり、上下左右を入れ替えたりすることで、あらたなデータを予め用意することなく、水増しが可能になります。\n",
    "\n",
    "以下のプログラムでは、make_dataset 関数が、特徴量同様に学習前に呼び出される関数です。この時、特徴量ではなく、画像のファイル名を作成し、酵母画像のファイル名とクラスの対応表を作成しています。\n",
    "画像は、PhotoID列をX, CellID列をYとすると、```data/images/C_yor202w_0_0_X_Y.png``` に入っています。よって、各細胞に対して、このファイル名と、クラスを割り当てます。クラスが\"no\", \"small\",\"medium\",\"large\" をそれぞれ別の次元とした4次元で表すのは、前節の事例と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dataset = pd.read_csv(os.path.join(dir, \"yeast_his3.csv\"))\n",
    "    for _, row in dataset[[\"Cgroup\",\"PhotoID\", \"CellID\"]].iterrows():\n",
    "        filename = \"C_yor202w_0_0_%d_%d\" % (row[\"PhotoID\"], row[\"CellID\"])\n",
    "        image_path = os.path.join(dir, \"images\", filename + \".png\")\n",
    "        y = [0, 0, 0, 0]\n",
    "        if row[\"Cgroup\"] == \"no\":\n",
    "            y = [1, 0, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"small\":\n",
    "            y = [0, 1, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"medium\":\n",
    "            y = [0, 0, 1, 0]\n",
    "        elif row[\"Cgroup\"] == \"large\":\n",
    "            y = [0, 0, 0, 1]\n",
    "        images.append(image_path)\n",
    "        labels.append(np.array(y))\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節同様に、訓練データ、バリデーションデータ、テストデータで分割を実施しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data 相当。\n",
    "datadir = \"../data\"\n",
    "X, y = make_dataset(datadir)\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    X, y, test_size = 0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節では、各バッチでは、DatasetFolder内の値を読み出していました。ここでも同様ですが、前節では、値を読み出すときには、PyTorchのTensor型に変換をしていたところを\n",
    "\n",
    "* 指定したパスの画像情報を読み出す (pil_loader関数)\n",
    "* 必要に応じて、画像の大きさを変換する (後述)。もしくは、水増しを行う。\n",
    "* 色の正規化を行う（後述）\n",
    "\n",
    "などの操作を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y, loader, transform=None, target_transform=None):\n",
    "        self.loader = loader\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index]\n",
    "        target = self.targets[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像読み込み時の、画像サイズの変換や色の補正を実施します。\n",
    "\n",
    "前節の事例では、特徴量も、クラスも、また、訓練、バリデーション、テストのいずれでも、一律に変換をしていました。ここでも訓練、バリデーション、テストのいずれでも基本的に一律の変換を実施しますが、特徴量は画像に変わっているため、画像特有の変換が実施できるように、それぞれ独立して定義を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の輝度値を補正するための関数を設定。\n",
    "# ResNet等のPre-trained model 学習時に利用されていた値\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# 画像の幅と高さ\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "# training (validation, testも同様）時に、画像に対して変換を加える場合は、\n",
    "# ここに記述する。ResizeやFlipなど。\n",
    "# 参照：https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "# 変換のあと、pytorchで扱うために、Tensor型に変換してあげる必要あり。\n",
    "# normalize(上記の関数)は、Tensor型に変換したあと、実施\n",
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize　# 後で画像を表示するために、一旦コメントアウトしておく。\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# クラスの変換。今回はPytorchのテンソルに変換するだけ\n",
    "# 他に必要な変換がある場合には、画像同様に記載可能。\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "        ToTensorOfTarget()\n",
    "])\n",
    "\n",
    "# 画像とクラスの読み込み用の関数を定義\n",
    "image_datasets = {\n",
    "    'train':YeastImageDataset(X_train, y_train,\n",
    "                              data_transforms['train'],\n",
    "                              target_transforms),\n",
    "    'val':YeastImageDataset(X_val, y_val,\n",
    "                             data_transforms['val'],\n",
    "                             target_transforms),\n",
    "    'test': YeastImageDataset(X_test, y_test,\n",
    "                             data_transforms['test'],\n",
    "                             target_transforms)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の準備が正しくできていることを確認するため、image_datasetsを呼び出して、帰ってくる画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_id = 3\n",
    "sample_img, _ = image_datasets['train'][sample_id]\n",
    "sample_img = transforms.ToPILImage('RGB')(sample_img) # Tensor を画像に変換（もとに戻す）\n",
    "plt.figure()\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を表示しやすいように、標準化をコメントアウトしていたので、戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチごとの読み込み用の設定。前節と同様。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める画像をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=64\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        image_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "        image_datasets['val'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        image_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークアーキテクチャ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像解析で広く使われるResNetなどの固定したアーキテクチャもありますが、ここでは汎用性に重きをおいて、シンプルなCNNの記載からスタートします。\n",
    "\n",
    "ここでは、\n",
    "```入力画像 -> Conv2D -> ReLU -> MaxPooling -> Conv2D -> ReLU -> MaxPooling -> Linear -> ReLU -> Linear ```\n",
    "という形のネットワークを組みます。\n",
    "\n",
    "ToDO: ConvolutionやPoolingが何であるかの説明。図が必要？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120) # channel_num * x * y\n",
    "        self.fc2 = nn.Linear(120, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ** convolution layers **\n",
    "        # 224 x 224 -> 112 x 112 \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # 112 x 112 -> 56 x 56\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # convert to 1-dim\n",
    "        x = x.view(-1, 16 * 56 * 56) # channel_num * x * y\n",
    "        # ** classification layers **\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv1とconv2が、2次元（＝画像）のコンボリューションを実施する層になっています。poolはプーリング層、fc1とfc2は全結合層です。\n",
    "* nn.Conv2d(3, 6, 5, padding=(2,2)): 3チャンネル(=RGB)の入力を、6チャネルに拡張。\n",
    "* nn.MaxPool2d(2, 2): 2x2のマス目でMaxPooling を実施。\n",
    "* ... \n",
    "と、利用する層の種類のの定義が行われています。\n",
    "\n",
    "上記の関数で定義した層を、どのように組み合わせるのか表したものが、forward 関数です。こちらでは、活性化関数としてReLUを利用して、\n",
    "* x = self.pool(F.relu(self.conv1(x))): 入力画像 -> Conv2D (conv1) -> ReLU -> MaxPooling (pool)\n",
    "* x = self.pool(F.relu(self.conv2(x))): -> Conv2D (conv2) -> ReLU -> MaxPooling (pool)\n",
    "* x.view(-1, 16 * 56 * 56): 平滑化\n",
    "* x = F.relu(self.fc1(x)): -> Linear -> ReLU\n",
    "* x = self.fc2(x): 最後のclassification層\n",
    "\n",
    "という形で、ネットワークの構成を順番に記載しています。\n",
    "\n",
    "前節同様に、作成したネットワークは、指定するデバイスに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "model = Net()\n",
    "model = model.to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ステップの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ステップの詳細を定義します。現在までに、ネットワークアーキテクチャの変更と、バッチごとのデータ取得の変更（画像を取得するように）を行いましたが、この学習しテップは、前節と全く同じ関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_accuracy(model, criterion, optimizer, phase):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train(False)\n",
    "\n",
    "    for inputs, labels in dataloaders[phase]:\n",
    "        labels = labels.float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # 訓練のときだけ履歴を保持する\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs)\n",
    "            _, classnums = torch.max(labels, 1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, classnums)\n",
    "\n",
    "        # 統計情報\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "    # サンプル数で割って平均を求める\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    print('On Test:\\tLoss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, outpath, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # 途中経過でモデル保存するための初期化\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # 時間計測用\n",
    "    end = time.time()\n",
    "\n",
    "    print(model)\n",
    "    print()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch:{}/{}'.format(epoch, num_epochs - 1), end=\"\")\n",
    "\n",
    "        # 各エポックで訓練+バリデーションを実行\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.float()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 訓練のときだけ履歴を保持する\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, classnums = torch.max(labels, 1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, classnums)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 統計情報\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "            # サンプル数で割って平均を求める\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('\\t{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}'.format(phase, epoch_loss, epoch_acc, time.time()-end), end=\"\")\n",
    "\n",
    "            # 精度が改善したらモデルを保存する\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            end = time.time()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深層学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行も、前節と同様です。つまり、深層学習を用いて画像の分類をする場合には、一見長く見えるプログラムの部分は変更の必要は無く、モデルやデータの読み込みを変更すればよいとわかります。\n",
    "\n",
    "各エポック、１０秒以上かかりますので、表示が出なくても焦らずに待ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/9\ttrain Loss: 0.7253 Acc: 0.7611 Time: 6.6630\tval Loss: 1.3202 Acc: 0.5263 Time: 1.2392\n",
      "Epoch:1/9\ttrain Loss: 0.5291 Acc: 0.7611 Time: 5.9355\tval Loss: 1.2957 Acc: 0.5000 Time: 1.1271\n",
      "Epoch:2/9\ttrain Loss: 0.5969 Acc: 0.7389 Time: 5.7072\tval Loss: 1.1912 Acc: 0.5000 Time: 1.1212\n",
      "Epoch:3/9\ttrain Loss: 0.4591 Acc: 0.8761 Time: 5.8885\tval Loss: 1.4049 Acc: 0.5132 Time: 1.2014\n",
      "Epoch:4/9\ttrain Loss: 0.3345 Acc: 0.8761 Time: 5.6536\tval Loss: 1.7908 Acc: 0.5132 Time: 1.2147\n",
      "Epoch:5/9\ttrain Loss: 0.2838 Acc: 0.8982 Time: 5.8146\tval Loss: 2.0115 Acc: 0.5526 Time: 1.2042\n",
      "Epoch:6/9\ttrain Loss: 0.2724 Acc: 0.8805 Time: 5.9603\tval Loss: 2.3191 Acc: 0.5526 Time: 1.1781\n",
      "Epoch:7/9\ttrain Loss: 0.2286 Acc: 0.9204 Time: 5.9380\tval Loss: 2.3066 Acc: 0.5789 Time: 1.1940\n",
      "Epoch:8/9\ttrain Loss: 0.1692 Acc: 0.9425 Time: 5.8779\tval Loss: 2.2008 Acc: 0.5132 Time: 1.2287\n",
      "Epoch:9/9\ttrain Loss: 0.1517 Acc: 0.9425 Time: 5.4992\tval Loss: 2.2733 Acc: 0.5263 Time: 1.4703\n",
      "\n",
      "Training complete in 1m 11s\n",
      "Best val acc: 0.5789\n",
      "On Test:\tLoss: 2.6149 Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "# Loss関数の定義。\n",
    "# Regression なので、CrossEntropy から、MSELossに変更\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer の定義\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "# 10 エポックごとに学習率を0.1倍する\n",
    "# 値は、ここでは固定してしまっているが、本来は可変。\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "# 実際の学習を実施する\n",
    "# 結果出力用ファイルのprefix\n",
    "outpath = os.path.join(outdir, \"cnn_b%d_lr%f_m%f_e%d\" % (batch_size, lr, momentum, epochs))\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, outpath, num_epochs=epochs)\n",
    "# 学習が終わったら、結果を保存する。\n",
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
