{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 細胞画像から細胞状態を直接予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今までは、細胞の大きさなどを観測した後に、芽の大きさで細胞周期を分けることを考えていましたが、ここでは、画像から直接細胞状態を推定する予測器を作成します。手間のかかる特徴量の抽出を無くせるという利点がある一方で、どの特徴が重要で分類できたのかは分かりにくくなるので、目的によって、適切に使い分けてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深層学習のサンプルとして、数字のMNIST、画像のImageNetなどの定形データに対する解析方法は、いずれの深層学習フレームワークでもドキュメントに書かれていますが、データ形式が少し変化したりすると、とたんにドキュメントが少なくなる現状のため、この講義では、生命科学ではよくあるだろうシチュエーションのデータ形式を考えつつ、サンプルを用意します。難解だとおもったら、PyTorchのチュートリアルなどを見て、再度このドキュメント・プログラムを見てもらえればと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2節同様に、利用するライブラリ一群を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特徴量から読み込んだ事例では、学習開始前に全てのデータを読み込み、学習時には、そこからバッチ毎にデータを読み込んでいました。画像の場合も同様ですが、ここでは、大規模データに対応できる工夫を導入します。\n",
    "\n",
    "画像や動画の場合には、枚数が多くなるとメモリに乗らない分量の大規模なデータになることがあります。このような場合には、学習前に全てのデータを読み込むことはできません。そこで、学習前にはファイル名（あるいは、ファイル名を知るために必要な値）だけを読み込み、バッチ毎に、バッチ内にあるサンプルの画像や動画を読み込みます。これにより、バッチ対象となるデータが読み込みさえすれば、学習を進めることができるので、全データ分のメモリが用意できなくても学習が可能です。\n",
    "\n",
    "さらに、このバッチごとの読み込みには複数の利点があります。\n",
    "\n",
    "* 深層学習では、高速化のためCPUではなくGPUを利用した計算が行われますが、GPUの欠点として、メモリが少ないことが挙げられます。たとえば、現在よく使われるNVIDIA社のGTX1080で8GB、サーバ用途で利用されるNVIDIA社のTESLA V100で16GB〜32GBと、CPUから利用できるメモリに比べると少々少なくなっています。バッチごとのデータ読み込みが可能になることで、メモリ量が限られた環境でも、効率良い学習が可能になります。\n",
    "* データの擬似的な拡張(水増し：Augmentation)との相性が良いです。例えば、画像解析を考えた場合に、上下左右の反転をしたり、回転をしても、同一のクラスとして認識して欲しい場合が多くあります（カメラを傾けても、ネコはネコなので）。この場合、画像を適当な角度で回転して、学習しても構わないことになります。予め、様々な角度の画像を用意しておくことも、一つの作戦ですが、ただでさえ枚数が多い画像が更に多くなって、ハードディスク容量の圧迫に繋がる可能性があります。そこで、バッチ毎に画像を読み込む際に、乱数を発生させて、適当な角度に回転したり、上下左右を入れ替えたりすることで、あらたなデータを予め用意することなく、水増しが可能になります。\n",
    "\n",
    "以下のプログラムでは、make_dataset 関数が、特徴量同様に学習前に呼び出される関数です。この時、特徴量ではなく、画像のファイル名を作成し、酵母画像のファイル名とクラスの対応表を作成しています。\n",
    "画像は、PhotoID列をX, CellID列をYとすると、```data/images/C_yor202w_0_0_X_Y.png``` に入っています。よって、各細胞に対して、このファイル名と、クラスを割り当てます。クラスが\"no\", \"small\",\"medium\",\"large\" をそれぞれ別の次元とした4次元で表すのは、前節の事例と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dataset = pd.read_csv(os.path.join(dir, \"yeast_his3.csv\"))\n",
    "    for _, row in dataset[[\"Cgroup\",\"PhotoID\", \"CellID\"]].iterrows():\n",
    "        filename = \"C_yor202w_0_0_%d_%d\" % (row[\"PhotoID\"], row[\"CellID\"])\n",
    "        image_path = os.path.join(dir, \"images\", filename + \".png\")\n",
    "        y = [0, 0, 0, 0]\n",
    "        if row[\"Cgroup\"] == \"no\":\n",
    "            y = [1, 0, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"small\":\n",
    "            y = [0, 1, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"medium\":\n",
    "            y = [0, 0, 1, 0]\n",
    "        elif row[\"Cgroup\"] == \"large\":\n",
    "            y = [0, 0, 0, 1]\n",
    "        images.append(image_path)\n",
    "        labels.append(np.array(y))\n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節同様に、訓練データ、バリデーションデータ、テストデータで分割を実施しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data 相当。\n",
    "datadir = \"data\"\n",
    "X, y = make_dataset(datadir)\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    X, y, test_size = 0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節では、各バッチでは、DatasetFolder内の値を読み出していました。ここでも同様ですが、前節では、値を読み出すときには、PyTorchのTensor型に変換をしていたところを\n",
    "\n",
    "* 指定したパスの画像情報を読み出す (pil_loader関数)\n",
    "* 必要に応じて、画像の大きさを変換する (後述)。もしくは、水増しを行う。\n",
    "* 色の正規化を行う（後述）\n",
    "\n",
    "などの操作を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y, loader, transform=None, target_transform=None):\n",
    "        self.loader = loader\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index]\n",
    "        target = self.targets[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像読み込み時の、画像サイズの変換や色の補正を実施します。\n",
    "\n",
    "前節の事例では、特徴量も、クラスも、また、訓練、バリデーション、テストのいずれでも、一律に変換をしていました。ここでも訓練、バリデーション、テストのいずれでも基本的に一律の変換を実施しますが、特徴量は画像に変わっているため、画像特有の変換が実施できるように、それぞれ独立して定義を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の輝度値を補正するための関数を設定。\n",
    "# ResNet等のPre-trained model 学習時に利用されていた値\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# 画像の幅と高さ\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "# training (validation, testも同様）時に、画像に対して変換を加える場合は、\n",
    "# ここに記述する。ResizeやFlipなど。\n",
    "# 参照：https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "# 変換のあと、pytorchで扱うために、Tensor型に変換してあげる必要あり。\n",
    "# normalize(上記の関数)は、Tensor型に変換したあと、実施\n",
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize　# 後で画像を表示するために、一旦コメントアウトしておく。\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# クラスの変換。今回はPytorchのテンソルに変換するだけ\n",
    "# 他に必要な変換がある場合には、画像同様に記載可能。\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "        ToTensorOfTarget()\n",
    "])\n",
    "\n",
    "# 画像とクラスの読み込み用の関数を定義\n",
    "image_datasets = {\n",
    "    'train':DatasetFolder(X_train, y_train, pil_loader,\n",
    "                              data_transforms['train'],\n",
    "                              target_transforms),\n",
    "    'val':DatasetFolder(X_val, y_val, pil_loader,\n",
    "                             data_transforms['val'],\n",
    "                             target_transforms),\n",
    "    'test': DatasetFolder(X_test, y_test, pil_loader,\n",
    "                             data_transforms['test'],\n",
    "                             target_transforms)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の準備が正しくできていることを確認するため、image_datasetsを呼び出して、帰ってくる画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_id = 3\n",
    "sample_img, _ = image_datasets['train'][sample_id]\n",
    "sample_img = transforms.ToPILImage('RGB')(sample_img) # Tensor を画像に変換（もとに戻す）\n",
    "plt.figure()\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を表示しやすいように、標準化をコメントアウトしていたので、戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バッチごとの読み込み用の設定。前節と同様。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める画像をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=64\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        image_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "        image_datasets['val'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        image_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークアーキテクチャ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像解析で広く使われるResNetなどの固定したアーキテクチャもありますが、ここでは汎用性に重きをおいて、シンプルなCNNの記載からスタートします。\n",
    "\n",
    "ここでは、\n",
    "```入力画像 -> Conv2D -> ReLU -> MaxPooling -> Conv2D -> ReLU -> MaxPooling -> Linear -> ReLU -> Linear ```\n",
    "という形のネットワークを組みます。\n",
    "\n",
    "ToDO: ConvolutionやPoolingが何であるかの説明。図が必要？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120) # channel_num * x * y\n",
    "        self.fc2 = nn.Linear(120, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ** convolution layers **\n",
    "        # 224 x 224 -> 112 x 112 \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # 112 x 112 -> 56 x 56\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # convert to 1-dim\n",
    "        x = x.view(-1, 16 * 56 * 56) # channel_num * x * y\n",
    "        # ** classification layers **\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv1とconv2が、2次元（＝画像）のコンボリューションを実施する層になっています。poolはプーリング層、fc1とfc2は全結合層です。\n",
    "* nn.Conv2d(3, 6, 5, padding=(2,2)): 3チャンネル(=RGB)の入力を、6チャネルに拡張。\n",
    "* nn.MaxPool2d(2, 2): 2x2のマス目でMaxPooling を実施。\n",
    "* ... \n",
    "と、利用する層の種類のの定義が行われています。\n",
    "\n",
    "上記の関数で定義した層を、どのように組み合わせるのか表したものが、forward 関数です。こちらでは、活性化関数としてReLUを利用して、\n",
    "* x = self.pool(F.relu(self.conv1(x))): 入力画像 -> Conv2D (conv1) -> ReLU -> MaxPooling (pool)\n",
    "* x = self.pool(F.relu(self.conv2(x))): -> Conv2D (conv2) -> ReLU -> MaxPooling (pool)\n",
    "* x.view(-1, 16 * 56 * 56): 平滑化\n",
    "* x = F.relu(self.fc1(x)): -> Linear -> ReLU\n",
    "* x = self.fc2(x): 最後のclassification層\n",
    "\n",
    "という形で、ネットワークの構成を順番に記載しています。\n",
    "\n",
    "前節同様に、作成したネットワークは、指定するデバイスに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "model = Net()\n",
    "model = model.to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ステップの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ステップの詳細を定義します。現在までに、ネットワークアーキテクチャの変更と、バッチごとのデータ取得の変更（画像を取得するように）を行いましたが、この学習しテップは、前節と全く同じ関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_accuracy(model, criterion, optimizer, phase):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train(False)\n",
    "\n",
    "    for inputs, labels in dataloaders[phase]:\n",
    "        labels = labels.float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # 訓練のときだけ履歴を保持する\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs)\n",
    "            _, classnums = torch.max(labels, 1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, classnums)\n",
    "\n",
    "        # 統計情報\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "    # サンプル数で割って平均を求める\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    print('On Test:\\tLoss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, outpath, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # 途中経過でモデル保存するための初期化\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # 時間計測用\n",
    "    end = time.time()\n",
    "\n",
    "    print(model)\n",
    "    print()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch:{}/{}'.format(epoch, num_epochs - 1), end=\"\")\n",
    "\n",
    "        # 各エポックで訓練+バリデーションを実行\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.float()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 訓練のときだけ履歴を保持する\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, classnums = torch.max(labels, 1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, classnums)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 統計情報\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "            # サンプル数で割って平均を求める\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('\\t{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}'.format(phase, epoch_loss, epoch_acc, time.time()-end), end=\"\")\n",
    "\n",
    "            # 精度が改善したらモデルを保存する\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            end = time.time()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深層学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行も、前節と同様です。つまり、深層学習を用いて画像の分類をする場合には、一見長く見えるプログラムの部分は変更の必要は無く、モデルやデータの読み込みを変更すればよいとわかります。\n",
    "\n",
    "各エポック、１０秒以上かかりますので、表示が出なくても焦らずに待ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/19\ttrain Loss: 1.3651 Acc: 0.3274 Time: 6.5277\tval Loss: 1.3378 Acc: 0.2895 Time: 1.2515\n",
      "Epoch:1/19\ttrain Loss: 1.3006 Acc: 0.3673 Time: 6.8330\tval Loss: 1.2468 Acc: 0.4605 Time: 1.1335\n",
      "Epoch:2/19\ttrain Loss: 1.1379 Acc: 0.5619 Time: 6.6124\tval Loss: 1.1576 Acc: 0.5132 Time: 1.4079\n",
      "Epoch:3/19\ttrain Loss: 0.8897 Acc: 0.6372 Time: 7.0189\tval Loss: 1.1721 Acc: 0.5526 Time: 1.3390\n",
      "Epoch:4/19\ttrain Loss: 0.7194 Acc: 0.6814 Time: 6.9666\tval Loss: 1.3092 Acc: 0.5000 Time: 1.3373\n",
      "Epoch:5/19\ttrain Loss: 0.8909 Acc: 0.6858 Time: 7.0082\tval Loss: 1.2163 Acc: 0.4868 Time: 1.3852\n",
      "Epoch:6/19\ttrain Loss: 0.6414 Acc: 0.7522 Time: 6.6887\tval Loss: 1.3009 Acc: 0.4868 Time: 1.4197\n",
      "Epoch:7/19\ttrain Loss: 0.5506 Acc: 0.7522 Time: 6.7281\tval Loss: 1.2227 Acc: 0.4737 Time: 1.2817\n",
      "Epoch:8/19\ttrain Loss: 0.4703 Acc: 0.8274 Time: 5.6623\tval Loss: 1.3741 Acc: 0.4868 Time: 1.1076\n",
      "Epoch:9/19\ttrain Loss: 0.4075 Acc: 0.8319 Time: 5.7541\tval Loss: 1.6754 Acc: 0.5000 Time: 1.2718\n",
      "Epoch:10/19\ttrain Loss: 0.3435 Acc: 0.8584 Time: 6.7778\tval Loss: 1.7277 Acc: 0.4737 Time: 1.2272\n",
      "Epoch:11/19\ttrain Loss: 0.3157 Acc: 0.8805 Time: 6.0750\tval Loss: 1.8456 Acc: 0.5000 Time: 1.2323\n",
      "Epoch:12/19\ttrain Loss: 0.2459 Acc: 0.9159 Time: 8.0303\tval Loss: 1.9894 Acc: 0.5263 Time: 1.3205\n",
      "Epoch:13/19\ttrain Loss: 0.2451 Acc: 0.9027 Time: 6.8446\tval Loss: 1.9428 Acc: 0.5132 Time: 1.3636\n",
      "Epoch:14/19\ttrain Loss: 0.2411 Acc: 0.9115 Time: 6.6978\tval Loss: 2.2018 Acc: 0.5395 Time: 1.4217\n",
      "Epoch:15/19\ttrain Loss: 0.2796 Acc: 0.8761 Time: 6.8220\tval Loss: 1.9947 Acc: 0.5263 Time: 1.3088\n",
      "Epoch:16/19\ttrain Loss: 0.1962 Acc: 0.9248 Time: 6.1655\tval Loss: 2.1358 Acc: 0.5789 Time: 1.2481\n",
      "Epoch:17/19\ttrain Loss: 0.2379 Acc: 0.8982 Time: 6.3516\tval Loss: 2.1852 Acc: 0.5263 Time: 1.3408\n",
      "Epoch:18/19\ttrain Loss: 0.1717 Acc: 0.9336 Time: 6.3704\tval Loss: 2.3151 Acc: 0.5789 Time: 1.3107\n",
      "Epoch:19/19\ttrain Loss: 0.2042 Acc: 0.9292 Time: 6.5424\tval Loss: 2.4381 Acc: 0.5000 Time: 1.3197\n",
      "\n",
      "Training complete in 2m 39s\n",
      "Best val acc: 0.5789\n",
      "On Test:\tLoss: 1.2252 Acc: 0.6316\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "# モデルの初期化\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss関数の定義。\n",
    "# Regression なので、CrossEntropy から、MSELossに変更\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer の定義\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "# 10 エポックごとに学習率を0.1倍する\n",
    "# 値は、ここでは固定してしまっているが、本来は可変。\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "# 実際の学習を実施する\n",
    "# 結果出力用ファイルのprefix\n",
    "outpath = os.path.join(outdir, \"cnn_b%d_lr%f_m%f_e%d\" % (batch_size, lr, momentum, epochs))\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, outpath, num_epochs=epochs)\n",
    "# 学習が終わったら、結果を保存する。\n",
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私が実験した範囲では、強い初期値依存性があるので、何度か繰り返してみて、結果を確認してみてください。\n",
    "\n",
    "多くのケースで、訓練データでは精度が高くなり（０．８等を超える）ますが、バリデーションデータやテストデータでは、訓練データに比べると低い（0.5など）値となります。この様な状態は、過学習(overfit)である可能性が高いです。深層学習では、このようなシンプルなモデルでもパラメータ数がデータ数に比べて極端に多いので、頻繁に過学習が起こります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation (水増し)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習を避ける一つの方法として、画像の水増しがあります。ここでは、データ読み込み時に水増しをしてみましょう。\n",
    "RandomHorizontalFlip()で左右反転、RandomRotationで回転を行って、向き依存性を解消することと、サンプル画像の数を増やしています。\n",
    "\n",
    "バリデーションやテストフェーズでは、水増しを行う必要はありません（これらの画像の精度を判断したいので）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/19\ttrain Loss: 1.6472 Acc: 0.2611 Time: 6.0189\tval Loss: 1.3525 Acc: 0.3553 Time: 1.2209\n",
      "Epoch:1/19\ttrain Loss: 1.3800 Acc: 0.3850 Time: 5.9550\tval Loss: 1.3149 Acc: 0.3684 Time: 1.2073\n",
      "Epoch:2/19\ttrain Loss: 1.1771 Acc: 0.5088 Time: 5.9140\tval Loss: 1.3169 Acc: 0.3158 Time: 1.2184\n",
      "Epoch:3/19\ttrain Loss: 1.0301 Acc: 0.5531 Time: 5.2286\tval Loss: 1.2930 Acc: 0.3684 Time: 1.2204\n",
      "Epoch:4/19\ttrain Loss: 0.8683 Acc: 0.6549 Time: 6.1033\tval Loss: 1.2588 Acc: 0.4211 Time: 1.2018\n",
      "Epoch:5/19\ttrain Loss: 0.7370 Acc: 0.7345 Time: 5.9110\tval Loss: 1.3158 Acc: 0.4605 Time: 1.2038\n",
      "Epoch:6/19\ttrain Loss: 0.6543 Acc: 0.7389 Time: 6.3290\tval Loss: 1.2981 Acc: 0.5000 Time: 1.4066\n",
      "Epoch:7/19\ttrain Loss: 0.5541 Acc: 0.7876 Time: 7.4174\tval Loss: 1.3588 Acc: 0.4737 Time: 1.4404\n",
      "Epoch:8/19\ttrain Loss: 0.5466 Acc: 0.7611 Time: 6.8996\tval Loss: 1.3741 Acc: 0.4605 Time: 1.3767\n",
      "Epoch:9/19\ttrain Loss: 0.4971 Acc: 0.8230 Time: 7.0355\tval Loss: 1.4164 Acc: 0.5132 Time: 1.3433\n",
      "Epoch:10/19\ttrain Loss: 0.4207 Acc: 0.8363 Time: 6.4061\tval Loss: 1.4567 Acc: 0.4737 Time: 1.2354\n",
      "Epoch:11/19\ttrain Loss: 0.4108 Acc: 0.8407 Time: 6.3240\tval Loss: 1.4451 Acc: 0.5132 Time: 1.2455\n",
      "Epoch:12/19\ttrain Loss: 0.3506 Acc: 0.8850 Time: 6.1547\tval Loss: 1.5044 Acc: 0.4737 Time: 1.2272\n",
      "Epoch:13/19\ttrain Loss: 0.3241 Acc: 0.8894 Time: 6.0963\tval Loss: 1.5419 Acc: 0.4605 Time: 1.3117\n",
      "Epoch:14/19\ttrain Loss: 0.2998 Acc: 0.9159 Time: 6.4706\tval Loss: 1.5595 Acc: 0.4868 Time: 1.2390\n",
      "Epoch:15/19\ttrain Loss: 0.2802 Acc: 0.9248 Time: 6.2417\tval Loss: 1.6367 Acc: 0.4868 Time: 1.3858\n",
      "Epoch:16/19\ttrain Loss: 0.2575 Acc: 0.9159 Time: 6.4845\tval Loss: 1.6706 Acc: 0.5132 Time: 1.5379\n",
      "Epoch:17/19\ttrain Loss: 0.2374 Acc: 0.9248 Time: 6.8959\tval Loss: 1.7210 Acc: 0.5263 Time: 1.4815\n",
      "Epoch:18/19\ttrain Loss: 0.2358 Acc: 0.9159 Time: 6.4032\tval Loss: 1.7811 Acc: 0.4737 Time: 1.0284\n",
      "Epoch:19/19\ttrain Loss: 0.2216 Acc: 0.9292 Time: 5.6954\tval Loss: 1.7772 Acc: 0.5263 Time: 1.3558\n",
      "\n",
      "Training complete in 2m 32s\n",
      "Best val acc: 0.5263\n",
      "On Test:\tLoss: 1.1529 Acc: 0.6053\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    # training data用。必要ならFlipやリサイズを行う\n",
    "    # このサンプルでは、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 以下は、水増し前と同じ。\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.03\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss関数の定義。\n",
    "# Regression なので、CrossEntropy から、MSELossに変更\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer の定義\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "# 10 エポックごとに学習率を0.1倍する\n",
    "# 値は、ここでは固定してしまっているが、本来は可変。\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "# 実際の学習を実施する\n",
    "# 結果出力用ファイルのprefix\n",
    "outpath = os.path.join(outdir, \"cnn_b%d_lr%f_m%f_e%d\" % (batch_size, lr, momentum, epochs))\n",
    "# 深層学習の実行\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, outpath, num_epochs=epochs)\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本質的に画像の枚数が不十分であることもあり、十分な精度向上は見込めませんが、手順として、このようなことが行われるということを認識して頂ければと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 積み残しの課題\n",
    "\n",
    "何点か、このテキストで積み残している課題です。\n",
    "1. ResNet等頻繁に利用されているモデルの利用。\n",
    "2. それらを用いた転移学習。\n",
    "3. 核以外の染色画像の利用\n",
    "\n",
    "学習に関して本質的に対処が必要な問題として\n",
    "1. 画像の枚数の確保\n",
    "2. 今回は顕微鏡画像から切り出した酵母の細胞画像を利用しているが、同一視野の画像は類似の傾向があると考えられるので、その補正（テスト画像選択時に、同一視野の画像を全て除くなど）\n",
    "\n",
    "などがあります。学習時に意図しないバイアスは頻繁に入りうるので、注意をする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
