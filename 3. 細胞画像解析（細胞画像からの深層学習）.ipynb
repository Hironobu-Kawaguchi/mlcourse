{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 細胞画像から細胞状態を直接予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今までは、細胞の大きさなどを観測した後に、芽の大きさで細胞周期を分けることを考えていましたが、ここでは、画像から直接細胞状態を推定する予測器を作成します。手間のかかる特徴量の抽出を無くせるという利点がある一方で、どの特徴が重要で分類できたのかは分かりにくくなるので、目的によって、適切に使い分けてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手書き文字（数字）認識のMNISTや画像分類のImageNetなど、機械学習でよく用いられているデータセットを用いた解析は、いずれの深層学習のフレームワークでもドキュメントやサンプルコードが豊富に存在しています。その一方で、データ形式が少し変化したりすると、とたんにドキュメントが少なくなります。この現状を踏まえ、本講義では、生命科学ではよくあるだろうシチュエーションのデータ形式を考えつつ、サンプルを用意します。難解だと思ったら、PyTorchのチュートリアルなどを見て、再度このドキュメント・プログラムを見てもらえればと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「2. 酵母画像解析（特徴量からの深層学習）」と同様に、利用するライブラリ一群を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "酵母の細胞の特徴量を解析した事例（2. 酵母画像解析（特徴量からの深層学習））では、学習開始前に全てのデータを読み込み、学習時には、そこからバッチ毎にデータを読み込んでいました。画像の場合も同様ですが、ここでは、大規模なデータに対応できる工夫を導入します。\n",
    "\n",
    "画像や動画の場合には、枚数が多くなるとメモリに乗らない分量の大規模なデータになることがあります。このような場合には、学習前に全てのデータを読み込むことはできません。そこで、学習前にはファイル名（あるいは、ファイル名を知るために必要な値）だけを読み込み、バッチ毎に、バッチ内にあるサンプルの画像や動画を読み込みます。これにより、バッチ対象となるデータが読み込みさえすれば、学習を進めることができるので、全データ分のメモリが用意できなくても学習が可能です。\n",
    "\n",
    "さらに、このバッチごとの読み込みには複数の利点があります。\n",
    "\n",
    "* 深層学習では、高速化のためCPUではなくGPUを利用した計算が行われますが、GPUの欠点として、メモリが少ないことが挙げられます。たとえば、現在よく使われるNVIDIA社のGTX1080で8GB、サーバ用途で利用されるNVIDIA社のTESLA V100で16GB〜32GBと、CPUから利用できるメモリに比べると少々少なくなっています。バッチごとのデータ読み込みが可能になることで、メモリ量が限られた環境でも、効率良い学習が可能になります。\n",
    "* データの擬似的な拡張(水増し：Augmentation)との相性が良いです。例えば、画像解析を考えた場合に、上下左右の反転をしたり、回転をしても、同一のクラスとして認識して欲しい場合が多くあります（カメラを傾けても、ネコはネコなので）。この場合、画像を適当な角度で回転して、学習しても構わないことになります。予め、様々な角度の画像を用意しておくことも、一つの作戦ですが、ただでさえ枚数が多い画像が更に多くなって、ハードディスク容量の圧迫に繋がる可能性があります。そこで、バッチ毎に画像を読み込む際に、乱数を発生させて、適当な角度に回転したり、上下左右を入れ替えたりすることで、あらたなデータを予め用意することなく、水増しが可能になります。\n",
    "\n",
    "以下のプログラムでは、make_dataset 関数が、特徴量同様に学習前に呼び出される関数です。この時、特徴量ではなく、画像のファイル名を作成し、酵母画像のファイル名とクラスの対応表を作成しています。\n",
    "画像は、PhotoID列をX, CellID列をYとすると、```data/images/C_yor202w_0_0_X_Y.png``` に入っています。よって、各細胞に対して、このファイル名と、クラスを割り当てます。クラスが\"no\", \"small\",\"medium\",\"large\" をそれぞれ別の次元とした4次元で表すのは、前節の事例と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dataset = pd.read_csv(os.path.join(dir, \"yeast_his3.csv\"))\n",
    "    for _, row in dataset[[\"Cgroup\",\"PhotoID\", \"CellID\"]].iterrows():\n",
    "        filename = \"C_yor202w_0_0_%d_%d\" % (row[\"PhotoID\"], row[\"CellID\"])\n",
    "        image_path = os.path.join(dir, \"images\", filename + \".png\")\n",
    "        y = [0, 0, 0, 0]\n",
    "        if row[\"Cgroup\"] == \"no\":\n",
    "            y = [1, 0, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"small\":\n",
    "            y = [0, 1, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"medium\":\n",
    "            y = [0, 0, 1, 0]\n",
    "        elif row[\"Cgroup\"] == \"large\":\n",
    "            y = [0, 0, 0, 1]\n",
    "        images.append(image_path)\n",
    "        labels.append(np.array(y))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節同様に、訓練データ、バリデーションデータ、テストデータで分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data に相当。\n",
    "datadir = \"data\"\n",
    "X, y = make_dataset(datadir)\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    X, y, test_size = 0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節では、各バッチでは、DatasetFolderの``__getitem__``関数を呼び出すことで値を読み出していました（2節の「学習中のデータの読み込み（バッチごとの読み込み）」参照）。ここでも同様ですが、前節では、値を読み出すときには、PyTorchのTensor型に変換をしていたところを\n",
    "\n",
    "* 指定したパスの画像情報を読み出す (pil_loader関数)\n",
    "* 必要に応じて、画像の大きさを変換する (後述)。もしくは、水増しを行う。\n",
    "* 色の正規化を行う（後述）\n",
    "\n",
    "などの操作を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y, loader, transform=None, target_transform=None):\n",
    "        self.loader = loader\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index]\n",
    "        target = self.targets[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を読み込む際に、画像の大きさの変換や色の正規化を実施します。画像の大きさは、機械学習のベンチマークでよく使われる画像と同じ224x224に拡大しています。\n",
    "\n",
    "前節の事例では、特徴量も、クラスも、また、訓練、バリデーション、テストのいずれでも、一律に変換をしていました。ここでも訓練、バリデーション、テストのいずれでも基本的に一律の変換を実施しますが、特徴量は画像に変わっているため、画像特有の変換が実施できるように、それぞれ独立して定義を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の輝度値を補正するための関数を設定\n",
    "# ResNet等のPre-trained model 学習時に利用されていた値を利用\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# 変換後の画像の幅と高さ\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "# training (validation, testも同様）時に、画像に対して変換を加える場合は、\n",
    "# ここに記述する。ResizeやFlipなど。\n",
    "# 参照：https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "# 変換のあと、pytorchで扱うために、Tensor型に変換してあげる必要あり。\n",
    "# normalize(上記の関数)は、Tensor型に変換したあと、実施\n",
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize　# 後で画像を表示するために、一旦コメントアウトしておく。\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# クラスの変換。今回はPytorchのTensor型に変換するだけ\n",
    "# 他に必要な変換がある場合には、画像同様に記載可能。\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "        ToTensorOfTarget()\n",
    "])\n",
    "\n",
    "# 画像とクラスの読み込み用の関数を定義\n",
    "image_datasets = {\n",
    "    'train':DatasetFolder(X_train, y_train, pil_loader,\n",
    "                              data_transforms['train'],\n",
    "                              target_transforms),\n",
    "    'val':DatasetFolder(X_val, y_val, pil_loader,\n",
    "                             data_transforms['val'],\n",
    "                             target_transforms),\n",
    "    'test': DatasetFolder(X_test, y_test, pil_loader,\n",
    "                             data_transforms['test'],\n",
    "                             target_transforms)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の準備が正しくできていることを確認するため、image_datasetsを呼び出して、帰ってくる画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_id = 3\n",
    "sample_img, _ = image_datasets['train'][sample_id]\n",
    "sample_img = transforms.ToPILImage('RGB')(sample_img) # Tensor を画像に変換（もとに戻す）\n",
    "plt.figure()\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を表示しやすいように、標準化をコメントアウトしていたので、戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2節と同様、バッチごとの読み込み用の設定をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める画像をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=64\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        image_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "        image_datasets['val'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        image_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークアーキテクチャ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像解析で広く使われるResNetなどの固定したアーキテクチャもありますが、ここでは汎用性に重きをおいて、シンプルなCNNの記載からスタートします。\n",
    "\n",
    "ここでは、\n",
    "```入力画像 -> Conv2D -> ReLU -> MaxPooling -> Conv2D -> ReLU -> MaxPooling -> Linear -> ReLU -> Linear ```\n",
    "という形のネットワークを組みます。\n",
    "\n",
    "ToDO: ConvolutionやPoolingが何であるかの説明。図が必要？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120) # channel_num * x * y\n",
    "        self.fc2 = nn.Linear(120, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ** convolution layers **\n",
    "        # 224 x 224 -> 112 x 112 \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # 112 x 112 -> 56 x 56\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # convert to 1-dim\n",
    "        x = x.view(-1, 16 * 56 * 56) # channel_num * x * y\n",
    "        # ** classification layers **\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv1とconv2が、2次元（＝画像）のコンボリューションを実施する層になっています。poolはプーリング層、fc1とfc2は全結合層です。\n",
    "* nn.Conv2d(3, 6, 5, padding=(2,2)): 3チャンネル(=RGB)の入力を、6チャネルに拡張。\n",
    "* nn.MaxPool2d(2, 2): 2x2のマス目でMaxPooling を実施。\n",
    "* ... \n",
    "と、利用する層の種類を定義しています。\n",
    "\n",
    "上記の関数で定義した層を、どのように組み合わせるのか表したものが、forward 関数です。こちらでは、活性化関数としてReLUを利用して、\n",
    "* x = self.pool(F.relu(self.conv1(x))): 入力画像 -> Conv2D (conv1) -> ReLU -> MaxPooling (pool)\n",
    "* x = self.pool(F.relu(self.conv2(x))): -> Conv2D (conv2) -> ReLU -> MaxPooling (pool)\n",
    "* x.view(-1, 16 * 56 * 56): 平滑化\n",
    "* x = F.relu(self.fc1(x)): -> Linear -> ReLU\n",
    "* x = self.fc2(x): 最後のclassification層\n",
    "\n",
    "という形で、ネットワークの構成を順番に記載しています。\n",
    "\n",
    "前節同様に、作成したネットワークは、指定するデバイスに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "model = Net()\n",
    "model = model.to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ステップの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ステップの詳細を定義します。現在までに、ネットワークアーキテクチャの変更と、バッチごとのデータ取得を画像を取得するよう変更しましたが、この学習ステップは、前節と全く同じ関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_accuracy(model, criterion, optimizer, phase):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train(False)\n",
    "\n",
    "    for inputs, labels in dataloaders[phase]:\n",
    "        labels = labels.float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # 訓練のときだけ履歴を保持する\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs)\n",
    "            _, classnums = torch.max(labels, 1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, classnums)\n",
    "\n",
    "        # 統計情報\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "    # サンプル数で割って平均を求める\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    print('On Test:\\tLoss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # 途中経過でモデル保存するための初期化\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # 時間計測用\n",
    "    end = time.time()\n",
    "\n",
    "    print(model)\n",
    "    print()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch:{}/{}'.format(epoch, num_epochs - 1), end=\"\")\n",
    "\n",
    "        # 各エポックで訓練+バリデーションを実行\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.float()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 訓練のときだけ履歴を保持する\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, classnums = torch.max(labels, 1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, classnums)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 統計情報\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "            # サンプル数で割って平均を求める\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('\\t{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}'.format(phase, epoch_loss, epoch_acc, time.time()-end), end=\"\")\n",
    "\n",
    "            # 精度が改善したらモデルを保存する\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            end = time.time()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深層学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行も、前節と同様です。つまり、深層学習を用いて画像の分類をする場合には、一見長く見えるプログラムの部分は変更の必要は無く、モデルやデータの読み込みを変更すればよいとわかります。\n",
    "\n",
    "各エポック、１０秒以上かかりますので、表示が出なくても焦らずに待ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/19\ttrain Loss: 1.3706 Acc: 0.3097 Time: 6.3717\tval Loss: 1.3718 Acc: 0.3026 Time: 1.2864\n",
      "Epoch:1/19\ttrain Loss: 1.3095 Acc: 0.3761 Time: 6.0359\tval Loss: 1.3377 Acc: 0.2763 Time: 1.4365\n",
      "Epoch:2/19\ttrain Loss: 1.1745 Acc: 0.4735 Time: 6.7391\tval Loss: 1.2557 Acc: 0.3947 Time: 1.6872\n",
      "Epoch:3/19\ttrain Loss: 0.8864 Acc: 0.6150 Time: 7.0420\tval Loss: 1.1805 Acc: 0.4474 Time: 1.4591\n",
      "Epoch:4/19\ttrain Loss: 0.7390 Acc: 0.6814 Time: 6.2641\tval Loss: 1.2409 Acc: 0.4868 Time: 1.3010\n",
      "Epoch:5/19\ttrain Loss: 0.6692 Acc: 0.6903 Time: 6.4253\tval Loss: 1.2916 Acc: 0.5263 Time: 1.5387\n",
      "Epoch:6/19\ttrain Loss: 0.4689 Acc: 0.8142 Time: 7.6363\tval Loss: 1.4354 Acc: 0.5132 Time: 1.3003\n",
      "Epoch:7/19\ttrain Loss: 0.3752 Acc: 0.8407 Time: 6.2241\tval Loss: 1.5219 Acc: 0.5132 Time: 1.2804\n",
      "Epoch:8/19\ttrain Loss: 0.3139 Acc: 0.8628 Time: 6.0651\tval Loss: 1.7162 Acc: 0.4605 Time: 1.1074\n",
      "Epoch:9/19\ttrain Loss: 0.2444 Acc: 0.9071 Time: 5.5129\tval Loss: 1.8303 Acc: 0.4868 Time: 1.2850\n",
      "Epoch:10/19\ttrain Loss: 0.2101 Acc: 0.9115 Time: 6.1302\tval Loss: 1.9919 Acc: 0.4605 Time: 1.3160\n",
      "Epoch:11/19\ttrain Loss: 0.2118 Acc: 0.9159 Time: 6.0380\tval Loss: 2.0489 Acc: 0.5000 Time: 1.2760\n",
      "Epoch:12/19\ttrain Loss: 0.1858 Acc: 0.9027 Time: 5.9325\tval Loss: 2.2246 Acc: 0.5000 Time: 1.2800\n",
      "Epoch:13/19\ttrain Loss: 0.1448 Acc: 0.9381 Time: 5.8993\tval Loss: 2.3604 Acc: 0.4737 Time: 1.2450\n",
      "Epoch:14/19\ttrain Loss: 0.1182 Acc: 0.9646 Time: 5.8922\tval Loss: 2.3961 Acc: 0.5263 Time: 1.2464\n",
      "Epoch:15/19\ttrain Loss: 0.1802 Acc: 0.9292 Time: 6.1082\tval Loss: 2.4180 Acc: 0.4737 Time: 1.2397\n",
      "Epoch:16/19\ttrain Loss: 0.1401 Acc: 0.9513 Time: 5.9334\tval Loss: 2.4226 Acc: 0.5132 Time: 1.2281\n",
      "Epoch:17/19\ttrain Loss: 0.1457 Acc: 0.9425 Time: 6.3055\tval Loss: 2.5267 Acc: 0.5132 Time: 1.2630\n",
      "Epoch:18/19\ttrain Loss: 0.0999 Acc: 0.9602 Time: 5.8707\tval Loss: 2.5979 Acc: 0.5132 Time: 1.2705\n",
      "Epoch:19/19\ttrain Loss: 0.0640 Acc: 0.9823 Time: 6.1213\tval Loss: 2.7557 Acc: 0.5395 Time: 1.2267\n",
      "\n",
      "Training complete in 2m 31s\n",
      "Best val acc: 0.5395\n",
      "On Test:\tLoss: 2.9986 Acc: 0.5132\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "# モデルの初期化\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "# 損失関数、\n",
    "# パラメータの最適化方法、学習率の更新方法を定義。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "\n",
    "# 実際の学習を実施\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
    "# 学習が終わったら、結果を保存する。\n",
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私が実験した範囲では、強い初期値依存性があるので、何度か繰り返してみて、結果を確認してみてください。\n",
    "\n",
    "多くのケースで、train Accが0.8を超えるなど、訓練データでの精度が高い一方で、バリデーションデータやテストデータでは、Accが0.5程度と低い値となります。この様な状態は、過学習(overfit)である可能性が高いです。深層学習では、このようなシンプルなモデルでもパラメータ数がデータ数に比べて極端に多いので、頻繁に過学習が起こります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation (水増し)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習を避ける一つの方法として、画像の水増しがあります。ここでは、データ読み込み時に水増しをしてみましょう。\n",
    "RandomHorizontalFlip()で左右反転、RandomRotationで回転を行い、向き依存性を解消すると同時に、サンプル画像の数を増やします。\n",
    "\n",
    "データの水増しは訓練データに足してのみ実施すればよく、バリデーションやテストフェーズでは、水増しを行う必要はありません（これらの画像の精度を判断したいので）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/19\ttrain Loss: 1.3757 Acc: 0.3097 Time: 6.9075\tval Loss: 1.3710 Acc: 0.2895 Time: 1.1766\n",
      "Epoch:1/19\ttrain Loss: 1.3433 Acc: 0.3540 Time: 5.7842\tval Loss: 1.3451 Acc: 0.3684 Time: 1.2283\n",
      "Epoch:2/19\ttrain Loss: 1.1831 Acc: 0.4779 Time: 5.7623\tval Loss: 1.2359 Acc: 0.4079 Time: 1.2161\n",
      "Epoch:3/19\ttrain Loss: 0.7878 Acc: 0.6549 Time: 5.8163\tval Loss: 1.1793 Acc: 0.4605 Time: 1.2088\n",
      "Epoch:4/19\ttrain Loss: 1.7875 Acc: 0.5531 Time: 6.8574\tval Loss: 1.4031 Acc: 0.2763 Time: 1.9737\n",
      "Epoch:5/19\ttrain Loss: 1.3873 Acc: 0.3009 Time: 6.7862\tval Loss: 1.3905 Acc: 0.1974 Time: 1.1281\n",
      "Epoch:6/19\ttrain Loss: 1.3846 Acc: 0.3097 Time: 6.6493\tval Loss: 1.3852 Acc: 0.2895 Time: 1.4651\n",
      "Epoch:7/19\ttrain Loss: 1.3777 Acc: 0.3097 Time: 6.7258\tval Loss: 1.3787 Acc: 0.2895 Time: 1.3609\n",
      "Epoch:8/19\ttrain Loss: 1.3734 Acc: 0.3097 Time: 7.2357\tval Loss: 1.5470 Acc: 0.2895 Time: 1.3597\n",
      "Epoch:9/19\ttrain Loss: 1.3737 Acc: 0.3097 Time: 6.3311\tval Loss: 1.6082 Acc: 0.2895 Time: 1.3624\n",
      "Epoch:10/19\ttrain Loss: 1.3883 Acc: 0.2655 Time: 6.1673\tval Loss: 1.4823 Acc: 0.2895 Time: 1.3791\n",
      "Epoch:11/19\ttrain Loss: 1.3872 Acc: 0.2655 Time: 6.1853\tval Loss: 1.5153 Acc: 0.2895 Time: 1.2337\n",
      "Epoch:12/19\ttrain Loss: 1.3743 Acc: 0.2655 Time: 5.8043\tval Loss: 1.7455 Acc: 0.2895 Time: 1.2744\n",
      "Epoch:13/19\ttrain Loss: 1.3797 Acc: 0.3097 Time: 6.2318\tval Loss: 1.9486 Acc: 0.2895 Time: 1.3585\n",
      "Epoch:14/19\ttrain Loss: 1.3819 Acc: 0.2965 Time: 6.1053\tval Loss: 1.3772 Acc: 0.4079 Time: 1.2689\n",
      "Epoch:15/19\ttrain Loss: 1.3791 Acc: 0.2655 Time: 6.4979\tval Loss: 1.3772 Acc: 0.3026 Time: 1.2746\n",
      "Epoch:16/19\ttrain Loss: 1.3754 Acc: 0.3009 Time: 5.9856\tval Loss: 1.5457 Acc: 0.2895 Time: 1.1427\n",
      "Epoch:17/19\ttrain Loss: 1.3748 Acc: 0.3097 Time: 5.9763\tval Loss: 2.0087 Acc: 0.2895 Time: 1.5504\n",
      "Epoch:18/19\ttrain Loss: 1.3744 Acc: 0.3097 Time: 7.7875\tval Loss: 1.9858 Acc: 0.2895 Time: 1.5201\n",
      "Epoch:19/19\ttrain Loss: 1.3728 Acc: 0.3097 Time: 6.4870\tval Loss: 1.8569 Acc: 0.2895 Time: 1.3227\n",
      "\n",
      "Training complete in 2m 35s\n",
      "Best val acc: 0.4605\n",
      "On Test:\tLoss: 1.0426 Acc: 0.6053\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    # 訓練データ\n",
    "    # 水増し（左右反転、45度回転）を行う\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # バリデーションデータ\n",
    "    # 通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # テストデータ\n",
    "    # 通常はFlip等は行わない。\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 以下は、水増し前と同じ。\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.03\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "# 損失関数、最適化方法、学習率の更新方法を定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "\n",
    "# 深層学習の実行\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本質的に画像の枚数が不十分であることもあり、十分な精度向上は見込めませんが、手順として、このようなことが行われるということを認識して頂ければと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 積み残しの課題\n",
    "\n",
    "何点か、このテキストで積み残している課題です。\n",
    "1. ResNet等頻繁に利用されているモデルの利用。\n",
    "2. それらを用いた転移学習。\n",
    "3. 核以外の染色画像の利用\n",
    "\n",
    "学習に関して本質的に対処が必要な問題として\n",
    "1. 画像の枚数の確保\n",
    "2. 今回は顕微鏡画像から切り出した酵母の細胞画像を利用しているが、同一視野の画像は類似の傾向があると考えられるので、その補正（テスト画像選択時に、同一視野の画像を全て除くなど）\n",
    "\n",
    "などがあります。学習時に意図しないバイアスは頻繁に入りうるので、注意をする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
