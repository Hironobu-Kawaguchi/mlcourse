{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 細胞画像から細胞状態を直接予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今までは、細胞の大きさなどを観測した後に、芽の大きさで細胞周期を分けることを考えていましたが、ここでは、画像から直接細胞状態を推定する予測器を作成します。手間のかかる特徴量の抽出を無くせるという利点がある一方で、どの特徴が重要で分類できたのかは分かりにくくなるので、目的によって、適切に使い分けてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手書き文字（数字）認識のMNISTや画像分類のImageNetなど、機械学習でよく用いられているデータセットを用いた解析は、いずれの深層学習のフレームワークでもドキュメントやサンプルコードが豊富に存在しています。その一方で、データ形式が少し変化したりすると、とたんにドキュメントが少なくなります。この現状を踏まえ、本講義では、生命科学ではよくあるだろうシチュエーションのデータ形式を考えつつ、サンプルを用意します。難解だと思ったら、PyTorchのチュートリアルなどを見て、再度このドキュメント・プログラムを見てもらえればと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「2. 酵母画像解析（特徴量からの深層学習）」と同様に、利用するライブラリ一群を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "酵母の細胞の特徴量を解析した事例（2. 酵母画像解析（特徴量からの深層学習））では、学習開始前に全てのデータを読み込み、学習時には、そこからバッチ毎にデータを読み込んでいました。画像の場合も同様ですが、ここでは、大規模なデータに対応できる工夫を導入します。\n",
    "\n",
    "画像や動画の場合には、枚数が多くなるとメモリに乗らない分量の大規模なデータになることがあります。このような場合には、学習前に全てのデータを読み込むことはできません。そこで、学習前にはファイル名（あるいは、ファイル名を知るために必要な値）だけを読み込み、バッチ毎に、バッチ内にあるサンプルの画像や動画を読み込みます。これにより、バッチ対象となるデータが読み込みさえすれば、学習を進めることができるので、全データ分のメモリが用意できなくても学習が可能です。\n",
    "\n",
    "さらに、このバッチごとの読み込みには複数の利点があります。\n",
    "\n",
    "* 深層学習では、高速化のためCPUではなくGPUを利用した計算が行われますが、GPUの欠点として、メモリが少ないことが挙げられます。たとえば、現在よく使われるNVIDIA社のGTX1080で8GB、サーバ用途で利用されるNVIDIA社のTESLA V100で16GB〜32GBと、CPUから利用できるメモリに比べると少々少なくなっています。バッチごとのデータ読み込みが可能になることで、メモリ量が限られた環境でも、効率良い学習が可能になります。\n",
    "* データの擬似的な拡張(水増し：Augmentation)との相性が良いです。例えば、画像解析を考えた場合に、上下左右の反転をしたり、回転をしても、同一のクラスとして認識して欲しい場合が多くあります（カメラを傾けても、ネコはネコなので）。この場合、画像を適当な角度で回転して、学習しても構わないことになります。予め、様々な角度の画像を用意しておくことも、一つの作戦ですが、ただでさえ枚数が多い画像が更に多くなって、ハードディスク容量の圧迫に繋がる可能性があります。そこで、バッチ毎に画像を読み込む際に、乱数を発生させて、適当な角度に回転したり、上下左右を入れ替えたりすることで、あらたなデータを予め用意することなく、水増しが可能になります。\n",
    "\n",
    "以下のプログラムでは、make_dataset 関数が、特徴量同様に学習前に呼び出される関数です。この時、特徴量ではなく、画像のファイル名を作成し、酵母画像のファイル名とクラスの対応表を作成しています。\n",
    "画像は、PhotoID列をX, CellID列をYとすると、```data/images/C_yor202w_0_0_X_Y.png``` に入っています。よって、各細胞に対して、このファイル名と、クラスを割り当てます。クラスが\"no\", \"small\",\"medium\",\"large\" をそれぞれ別の次元とした4次元で表すのは、前節の事例と同じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    dataset = pd.read_csv(os.path.join(dir, \"yeast_his3.csv\"))\n",
    "    for _, row in dataset[[\"Cgroup\",\"PhotoID\", \"CellID\"]].iterrows():\n",
    "        filename = \"C_yor202w_0_0_%d_%d\" % (row[\"PhotoID\"], row[\"CellID\"])\n",
    "        image_path = os.path.join(dir, \"images\", filename + \".png\")\n",
    "        y = [0, 0, 0, 0]\n",
    "        if row[\"Cgroup\"] == \"no\":\n",
    "            y = [1, 0, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"small\":\n",
    "            y = [0, 1, 0, 0]\n",
    "        elif row[\"Cgroup\"] == \"medium\":\n",
    "            y = [0, 0, 1, 0]\n",
    "        elif row[\"Cgroup\"] == \"large\":\n",
    "            y = [0, 0, 0, 1]\n",
    "        images.append(image_path)\n",
    "        labels.append(np.array(y))\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節同様に、訓練データ、バリデーションデータ、テストデータで分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を、training, valid, testに分ける。ここでは、3:1:1 に分割。\n",
    "# training + valid が、機械学習の training data に相当。\n",
    "datadir = \"data\"\n",
    "X, y = make_dataset(datadir)\n",
    "X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
    "    X, y, test_size = 0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tmp, y_tmp, test_size = 0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前節では、各バッチでは、DatasetFolderの``__getitem__``関数を呼び出すことで値を読み出していました（2節の「学習中のデータの読み込み（バッチごとの読み込み）」参照）。ここでも同様ですが、前節では、値を読み出すときには、PyTorchのTensor型に変換をしていたところを\n",
    "\n",
    "* 指定したパスの画像情報を読み出す (pil_loader関数)\n",
    "* 必要に応じて、画像の大きさを変換する (後述)。もしくは、水増しを行う。\n",
    "* 色の正規化を行う（後述）\n",
    "\n",
    "などの操作を追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetFolder(data.Dataset):\n",
    "    def __init__(self, X, y, loader, transform=None, target_transform=None):\n",
    "        self.loader = loader\n",
    "        self.samples = X\n",
    "        self.targets = y\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.samples[index]\n",
    "        target = self.targets[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を読み込む際に、画像の大きさの変換や色の正規化を実施します。画像の大きさは、機械学習のベンチマークでよく使われる画像と同じ224x224に拡大しています。\n",
    "\n",
    "前節の事例では、特徴量も、クラスも、また、訓練、バリデーション、テストのいずれでも、一律に変換をしていました。ここでも訓練、バリデーション、テストのいずれでも基本的に一律の変換を実施しますが、特徴量は画像に変わっているため、画像特有の変換が実施できるように、それぞれ独立して定義を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の輝度値を補正するための関数を設定\n",
    "# ResNet等のPre-trained model 学習時に利用されていた値を利用\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# 変換後の画像の幅と高さ\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "\n",
    "# training (validation, testも同様）時に、画像に対して変換を加える場合は、\n",
    "# ここに記述する。ResizeやFlipなど。\n",
    "# 参照：https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "# 変換のあと、pytorchで扱うために、Tensor型に変換してあげる必要あり。\n",
    "# normalize(上記の関数)は、Tensor型に変換したあと、実施\n",
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        #normalize　# 後で画像を表示するために、一旦コメントアウトしておく。\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# クラスの変換。今回はPytorchのTensor型に変換するだけ\n",
    "# 他に必要な変換がある場合には、画像同様に記載可能。\n",
    "class ToTensorOfTarget(object):\n",
    "    def __call__(self, target):\n",
    "        return torch.from_numpy(target)\n",
    "\n",
    "target_transforms = transforms.Compose([\n",
    "        ToTensorOfTarget()\n",
    "])\n",
    "\n",
    "# 画像とクラスの読み込み用の関数を定義\n",
    "image_datasets = {\n",
    "    'train':DatasetFolder(X_train, y_train, pil_loader,\n",
    "                              data_transforms['train'],\n",
    "                              target_transforms),\n",
    "    'val':DatasetFolder(X_val, y_val, pil_loader,\n",
    "                             data_transforms['val'],\n",
    "                             target_transforms),\n",
    "    'test': DatasetFolder(X_test, y_test, pil_loader,\n",
    "                             data_transforms['test'],\n",
    "                             target_transforms)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の準備が正しくできていることを確認するため、image_datasetsを呼び出して、帰ってくる画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztfWvMbVtZ3vN+t71P1ARRe3IK2AMGm6hJj0qwidbaUm/E9tSmodBEQY1HE0lqYlMPalpjY6JWNDZtSDEQoaGgCV5IQ1uR1Gh/YD1QqiiigBA4wXPqFcPx7P1dRn+s9a79rOd73zHGnGut75tr7/kkM3OueRn38YznfceYc1kpBTNmzJjhOLjuBMyYMWNamElhxowZa5hJYcaMGWuYSWHGjBlrmElhxowZa5hJYcaMGWvYGSmY2deZ2QfM7INm9uiu4pkxY8Z2YbtYp2BmhwB+H8BXA/g4gN8E8LJSyu9uPbIZM2ZsFbtSCi8E8MFSyodLKbcBvAXAwzuKa8aMGVvE0Y7CfRaAj9HvjwP4suxmM7skV8ysO7Ih97buHxpWLYyaCouuDVFtURz6fG9eetOySXgzJoE/LqV8TuumXZFCE2b2CIBH/Pfh4aGfT/d6jsJKf7fCyX5rmFmHq8VVSlk958fR7+hahiiOi4sLXFxcrI79+sHBwdpewc/wntPg+1r5azl5OL5FZTwUvURzXYQ0JN6xadx0wCqlfLTnvl2RwuMAnkO/n708t0Ip5bUAXgvESmHGjBnXg12Rwm8CeL6ZPRcLMngpgH++i4h05Il+8/mhSiEzBbatFHSUzswCM6tK+01H5OyZMeFtwxSbcfXYCSmUUs7M7JUA/geAQwCvL6X8Tu2ZqHO1EJkNmVQ9ODi4dM8QUsjiHksKkcTOTAklgijfkUzP0p/J14hwoudbPhO93mN2zJgOduZTKKW8HcDbhz431KdQ69RKCrVz0fMafi19en1ZBqkyODg4WFMISgruG1DV4OeYCHzfKq8oHH6WjyO08lq7/6qIYQgJXhemnsZrczQyso7X+xw3OO38GSnwvZmKiNK3LVJQMjg4OFhzGHIYTBCtkbvHfGiN8NG9UXhDwqmdnzEtTIIUtoWow2e/e0khMye2RQq893hUOURhZfmPjjfB3JHvPewFKdQ6Jnfqw8PDlAyugxQADCIFnVpkslD/A4A1BcHxRSZBjzzdBQFkpsuM6WIypJCNclmny9SAkgDva4ThYV4VKTA5KBnUfrM5wR0uUhGRc7LXyVgjiCEEo87GGdPHZEihhlZn1Y6v5BCRxaakoMf8O+qs+rulFM7Pz9dMClYLPaaF3xepCf6tiqKGrIPXyGeMYokQpa03rE2e7UVWdlNKYy8mQwo1pVDrqKoSerYpkEJLKXiH9u38/DydlchIIeroQ52D/NwQU2BWBvuLyZBCLzJT4eDgYOVT2CYp8Hk/5vOaNj2fjdC9pHB+fn5ptPURt+ZTUH/EmHJWzH6BewOTI4WsQ3In5vPa4XuIIVIZGnePD6GHFDKC8M6q5oFPTTop+J7XNajpkZklni8nj1qZ95zTPPSA87mpCTHjajA5UmBEZkLNXHBCaBGDN/hs8ZIfa1rGdIhWGN5RuNN7uvxYzYeMFJhEAFya5pwxoweTIYWoA7W2SB0cHh52k4IqhSgdrfN6PSIY/812OXdUP46UApsTGSnwQii/18FqhNMX+Rt6FQ6fU39GppZULWQYQl6bmDib+Dz2IY2bYDKk4BhCBpFSUIKIfA9RmBw/ozalFj1XI4Xofp1NYGLgLTMflDicGNjRqHFn+aiVg5ZHL2bzYf8wOVKIoB265TOIzAh+jsNtkYJiExMiIxEmBCYh3SJTg2cnNJ3RrERGWjNmOCZDCtxYoxkCNQlcFbA6OD4+vqQU2DzgcFvTddkUX0/6fR+pkZr/QtWDKwYlDfYZOCH45r+5rHwGg8MYQoRR+ewKmyqUTeR6LzaN4yrSuAkmQwoRWmZD5ktQhVAzF3qgo252j0pkViWar1qeGTyDoKO9d/haepVM2GeRxTmlBjrj6jEJUtBRc4g/IVIM0fSjhs3oUQgtUogwZJFPzUGnx0wUWX6izcPpNZlmcrg3MZoUzOw5AN4I4H4ABcBrSyk/ZWY/CODbAfy/5a3fVxbfVhgSdpdjcch6BA6XEdndfJx1rizdvI/yMrQcanBycFXCjsoone6EZBOKMZPADGAzpXAG4HtKKe8xs88A8G4ze8fy2k+WUn58SGA1pdCaZagtTMpUQTalFt03VC3oFF7PpvdHadKy4vuZFPwjuFFadCFTLZ4hSqc11ThjfzCaFEopnwDwieXxX5rZ+7H4tPsoRKQwZMaB78s6nE7/+bkeouj1K3Be9IWmFilwB9M083Utt4gYMhXg6oLLISMEVRM1Bxn7U/Re9bVonfSgFveYZ3uxaRzbTONVKbmt+BTM7EEAXwzgNwB8OYBXmtk3A3gMCzXxZwPC2sh8GCLXtVNsSgocbpaXFikMMTO0jDhuv673Z+sZsrcpZ9x72Pgfoszs0wG8FcB3l1I+CeA1AD4PwENYKIlXJ889YmaPmdljPnrUiGAoQdTMh9qmC4J0G3Nv677atxMiIsrKKiufmjNWnx9LTH48Y/+xkVIws2MsCOFNpZSfB4BSyhN0/acB/Nfo2UL/+3B4eFii0XKoWqg1yshkiJRCph7GgMMZ6ltoIVIBOgWqZerrGDQ9OosxNM8R8c7YX2wy+2AAXgfg/aWUn6DzDyz9DQDwjQDeNzDckBB0n41smTLQ3zVSiFCz01v5ie6N1FEPUUThcd6ZHH3PC5j0q02aHvULRCpFkSmZmRz2E5sohS8H8E0AftvM3rs8930AXmZmD2ExTfkRAN/RCiizqzNCiGRz1Il6yKDH6ajXelEjGO7cGRH69Z5FUP4Mp1P9BGZ26e/5OA5Nl95XO19LnxJOze8xpIx7CGpTbBrHVaRx29hk9uF/AYhaxuD/egAuS91oRiFTCrpISdLZ5Ufwe/k5PReF3cqThsmjaM1k4vPRIiUOu3ae4zo/P18jBS0Hvb+mFFode1YK+4tJrGgE8nUKY5yKUWPsVQp8f3auFzWlUMtzRJARlAyikdkVAJsPThCqgoZ8f6FHKczYT0yeFIbY2xF6lMJ1oBVvLxkpMUTX+Xld+RitpeiFklArrTP2A3tPCrXGXFMMrfuysGqyuQe9nb11X9Qh/byaBsAdMlBS8I1fkmqRQ+R3UPUzk8P+YjKksC1op89UQXYuCzO6Xuus2T1ZZ87iUv+D3heRKcel+Y9IQU2WKC98HBFARBRZGdWQkdGUSKZ3ANpXTIIUIjt6VgrxLIjG3VIKSgw6q+E+i6gOMsxK4e7GJEgBuHqfAl+7DvT6FFoqJSIEHfUjUhi7NJwx+xTuTkyGFBjbUAljEXW+bIYiSndmFmySHnUWcjp6RnROm3+NKiNLL0/+eEv2BzQ98fbmcQyuKp57DZMjhZZiqH0roafSayNa1OCHzFJEHbi3IaoUb/kUNH2KyEcQLQfX/NV8E0wOajL0pjfLs57L8tNCzafTE8+MCZFC5NRiEsgWLOn9mWmQOcL03pZpsS2l0Osj6FUKNSLhdQ6Hh4dhHmtlxcdODmoy6DGrjiHx1MhP0eNHyoggI4+rUi2KIQPaLuMAJkQKjqFKgZ/bplJQUthnpcCd8/Dw8NI3GjWdEdHwx2I5XdnxrBT2F5MjBWCYT8Hv3xbUxubzPememk9BCZXTmeXVw+ePxXJaWgQ8+xT2G5MkhV2i1Rk2DbtXsQwNNzsX5WdM/FdNvjOmi70hhVZj5VE660RZZxnboSL7NfIJZPnpDTsKT1cg8l/LDZHMaoZl0LKuhXm3YxfkOKQ97BqTIYWWL6E3DCWGyAxokUCv+RDZr71KoXVPb8drKYUaKalPZoxSyMg4O67VpTosrxKbdvRdOwGvkognQwotbEsp9Gy92KRyxo4M2mmyPESdq6YUhm6tdN7NmJXCjEkhcgjWiG32A8wYio1Jwcw+AuAvAZwDOCulvMDMngngZwE8iMXXl15SBnzRWcLvkrU9XvFtqoSxiKR4Zq8rhiig2jMaH79BGW0cph/r/0fU0rwrYhobbs1MuQoSHTNrsgsHdoaNv+a8xN8rpTxUSnnB8vejAN5ZSnk+gHcuf8/YMjYluLGmw1ifz4z9wK7Mh4cBfNXy+A0AfhXA99YeyByNQxGphlYniUbWnhEkG7mjZzInXe2a2u6ZnyAjBPUveLh+TreWUtDnIkTldh2jcQ2cpshZ3PP8Jhg64rf8ZdvGNkihAPhlMysA/lNZfLr9/nLni85/hMX/Ta7BzB4B8Aiwvgw3uO9KzAe/vmtEpkKLPBxZ54qcjl4WnL/MTNmGs7FGEtdNAorZfKhjG6TwFaWUx83srwF4h5n9Hl8spZQlYUDOr/734fj4+N5zYW8BLfOh1fjUn5D5FTISjZY8z9h/bEwKpZTHl/snzewXALwQwBO2/P8HM3sAwJObxpNh17bumDAiEyLat5RCK+4xjlOOUwkhMyfcsRhdV4K423Avkt1GjkYz+zRb/OM0zOzTAHwNFn/+8jYAL1/e9nIAv7RJPFNBZLZsM8xtEFqPkzGLr/aV7Nq1XlNjambEjBibKoX7AfzCsrKPAPyXUsp/N7PfBPBzZvZtAD4K4CVjI4hGvSEdJ7J/h4yoWThZWvnZWhgZAegzkf2bOThrzsasI7NaANBtPrh66C2bTdFTR9l9m6A3X7tUFGyeXQWxbkQKpZQPA/hbwfk/AfCiTcLuxVWZD0PCy8yHMaTQimeM+ZB9sNUbX+agjMJis6EW7y5wFR3kXjQfJrOiMfKgD3WkDZGy+lyGIdLXO9V1yuVaIx4q+ceYCPuOKSiD68ZkSMHRSwh+L7A+yjnG2rM9BFFLe5SOLD2bKgWNm+PXkT6Ld+qkwHnQjrhJnFlYPXU8JO7M1FNMiVQnRwozdovrIAUmq6hzz5gWJkMK2zYf9Hev+ZA17rvZfODFY5mjsTY1OZsPdxcmQwqKscTA2AYpTLHyNb2tTrlLdbAPpNA7uxSd13DuBcUzGVJQpcDHQ/wMwOXlv6ocNM4ahjb2rLGNRfR85Cvg3z0keDeSQtZZa2UY3cfth8NTQmgRCD+zT5gMKTCGkoESgldYq/FGo0NPRWs8tXta4Wb3R+jt4Nn5q1IK3BFU1U21g2xCcNwOdCBqkcfQNF4FJkkKwLBZiAzbIIUpNuJMHdTuv0pSmBp6zYdWXmbz4YqRmQwXFxfh5pUX+ReyTrOJUuhtAFFj2wQ96mHTLXM0Dn1WTT8+l5mH0b3XgW0T3Gw+bBGbmA6KbSiFTZGRBKclOteTnlpH7dkcXIZMCC1iODg4wMXFxdo/WW+LFHSvxxGyZ3rCrNVBL/at82eYBClEnXsIIWRKIfIt8NQaN+oxFdrTeMYqh4gwont2RQrZlKS+C8HPjz03NVIYAjUpxmJKhDIJUgDGrVOINq2gTCmMbQRDUSOFmlLoVRFTJ4Xo/LaUQtSRssGlFc+u2kFvZ++J/6qIYzKk4NBOnvkU9IOijIgQWOICWFMJ/McqQwp+TEMaQgo1gtD8TZ0UavdNiRR4QMmey/wEtbbYwqwUAmxDKTCyjnPV5kPtmSGkUPNB6HZ4eBhuBwcHq/2uSCEKcx9IoRbmJphSZ+/FZEiBsQkZMLJO49d47/HqKNFy9A3Ftkihtm2qFDyMLOy7lRRmQlhgNCmY2d/E4r8dHM8D8K8BPAPAtwP4f8vz31dKeXsrvKySxqqEmv3tv6PnIjnJv/X+nnMZekghI7RtkoK+z8DEUHv3AcCayurpwEMIojfMLI5amNE5M+v6rFxvZ9e2wG0pU7abxLctjCaFUsoHADwEAGZ2COBxAL8A4FsA/GQp5cc3CLs6CkTXo87LDT0KT8mjphT4Gp8fqhY0/Cgt3Dk1Hz3bUFJgDDUffNMy3ieloO1J86R5663zrONrW8ryEsV3FQSxLfPhRQA+VEr56BhJDeyfUshIYaxJ0asE/HptDcGmpDDEfMjqYZ+UgpJbC7NS6MNLAbyZfr/SzL4ZwGMAvqcM/Mu4IWTQYtios0XXPN4es4HPXzUpqMS/aqXQWxf7Sgrb7IBX3Zm3hW38l+QJgH8E4FXLU68B8G8BlOX+1QC+NXhu9WcwUUfSivKpyPPz8+oI6g2YGz3bvywJvQNdXFw0JWVGHpKnS/dm5BGFrWnbNjHwLIQ+6+XAafO9+hgODw9xfn6edmjNXxTmUFKIwq91/qzT67moDqP69fNZGLXfXK4ZUWyDQLZFQttQCl8P4D2llCcAwPcAYGY/DeC/Rg8V+jOYo6OjItfWKsGdW0wIDG7Yek6PPUzvBDwlyeTAaxcUUQfXzp+RVlAOq2saTi2f3FE1Pu3EOhXpx0wGnt+o4fK9TgiHh4dVUojy2aMEWp2Mn9HOFhEA12lE9Nxp+XwElv0ZaUUbl2tGnqpQM2T3tX4PwTZI4WUg08GWfwKz/PmNWPwPRDe4EGvEsIxrrfN4442u+TmPw8NnpWBmq2O/T5/l81qh0V5H5Ci/fByFGeWRO73eVzMhWC1wObNSUHiZMyFoOfUQQnRvj1KodTxPs3Z+/vx8RAwcrrYBTp+aWVnny9IWneM0aSeP2lntXFRmm2IjUrDFH8B8NYDvoNM/ZmYPYWE+fESudUErhwtyGe9qzwV2eHi4OqcdmjdlcJXtKqM5Tj+vDbtGCDyyR3nlMDltLaVQcwZmaiEjBc6Dwp/nBV+1zp2VV9bpozCi+6POFh2zyuM6zYhBp1mjgUTbSKv+uFxdiXlZ1shg75VCKeVTAD5Lzn3TJmFSOGvHPIqdn58DuGwiRMugo86SkYKjt4L0nmh01w4cxaGjW5S3bKtNW9acjE6gpVxeg6BpYDJglaB1xKiRQvZcSxVEnb91rINBzZwA7qiGrE6jvNXymLVjJeBtjPK1+hiCSaxojCqHEdl8TAJKCPrdhSjsSD0A640iS1M2KmiHikZyvs7HkfLQBsmdWWcR1KzIljrz5uFrB4rKmX0Prc6dlZce63PbJoXsXBSeO7G5HHTg4LoZ2umUUHhwisplF+gNfxKkAMQJ9grQ6TAlgogUImnIUs1HSI+HK0fvjxpuVJlRh+LOyvdEslTznY3+LVJgp2Jt07SwzOU41BnboxSiuowafo0U9DntxFmHPz8/T69FpOD3cx41DZGazNqsgutWVZm2nx5y0LYZKZQofXcFKTgipcAVrnYuX8sKumU3KhFxGjOloOFHTsZIgipJ+blIKUR+iogsdPox8isomXk5Kumw2bANpaDXavdtQgq9SsEdqD64uHmq5ODXs3RrmlVdMLx9cf3vWin0YjKkwMgYOBr9M7UQNaZsROdj75zs1db4M6WgYWaEkMXNea8pBSYAJR+dfqxtDm6gGSlkI21WZ9nvFinwcba1TIahpMBT3U4I3B44ParoFJlSyNpeDxlEpLJLTIYUegqm1kgiE4LJIypUvcYNwDtNi2Bqlaod2s/xtQw1UoiuR2ZFLylw+qN0Xgcp8LldK4Xz83McHBzg7OxsdRzlNVIOUb1lxLAvmAwpKKLGkykFtXcjUuARL+tYUcNlwlAyiPYRMlMluq7p0t+12YaMAGukxmmP4uM4lQijMHokcNapolFYR1MfNVXNcednU0f9S+oPcVI4OzvD2dkZAODs7CxUIn6v/+ZjLpNIYWibiq7X2livKtkGJksKimyEzswHXQ7N92jHyTqT3x9VTlT5mt4I2eii+4wUetJdQ9RIM0QKR30tQ0igFk/tnJJP5BDMOn/Nwcj3OymUUnB0dBQOMOy/Yh8Et5PeMtkEuw5/cqSgo4g2CP/Ntm/NfOBrukbBEXVAPdb4/XqNFIZ0vizuiCA4/TXC4HTVlEJU1hqmdkQtg0w2a5lwfJpnvcbPRWXNaYmkfu03h6Wk4Hs3Q3h/cHCwIgReL9Mq4xZYEdXyqWWSobdOIkyOFByZXIqUgjes7GUpJQz1/NbkeWR7R407k3xa0T0dsPU7e3as+cBh6V7DGqMUFFoWESn0qJ+oPfhxpgyie33pts/InJ2drUjANyeOqIzZjImIc1NkSmpXimGypJAh63SZSqipB34+WmjE5BGhRhiRdNV8ZMRUG/kV2fmaVNZnVYXURtcawUSjXO3+KP4sj638e7iehxp5aTr5+5X+W0nBVYIrBScINidYOWTlGKWhhcyU2hUmQwq1kSFrFFmjz/wK0aYryzi+TL6zpI5kuoO94FkH8oacqQItH21YESIVxeF4nqdIChlR9CiIKB3ZM1qeR0dHMDOcnJykpOBqQo91y2Y+IoLqQS39tXIYi8mTQiuD2ogjR5AShfohtJN4epg4WseaXpahUaPg3z0Nf4hcjJQBd0RWSxpvqzNnhBE9o+f4t8ZbI8UaWfBxRMx6T3Re4+S2wv4E9zvwMf9WYvC9h63OUK0zThOrnmhA2CUmQQpmi6W5jmg0jDqfFi6vRMs2/g5ANEr7OZeKR0dHa/LSRxReIZjN+d++fXutoZQSz6Fn0GvaybkTcMNWkmQSi+zijBQ4nhYptNSD/s5IoPY7O1dTVpnKrI20AC517BopnJ6eXiKJjCh4wMrKMyv/qN4jgtkUkyCFbUALiNk5mono6Zi6NPjo6AhHR0fhsmFOh8PM1hqIKhknCn1Of48ZIfyZyITg8vFj3++CFKLwhiiD2haFUTvOEIXrhKrkGn2whpeP8yIoJmGvd4/P2x+nrVXXNaW0Ldx1pKANt0YKWUNW04EJ4fj4+FJDUN8CV5wTgtufTA4sKf1Z3nPesjw6ooYREUumvPxc1ok1/hopZM/z78wcqO17lEL2XEQ8DF3pycSg4Xn9OQHowOGKISMKbxdMFsAdAo/qT9N87aRgZq8H8A0AniylfNHy3DOx+N+HB7H4mMpLSil/ZosU/hSAFwN4CsArSinvGZIobpwt9gfW52S50fq5iBSihq3x8WjghHBycnJpZODXkDkPZrZqHNwo+OtR/K1D7UCcN5aIUZr9Pt+0TLghcj712MPX/ZAtelaREVotfS1l0EMgWZxcTvqsvjxWyp2XqLgNOCHox2x8c9Xg4fB7Fl4m0eDCxw51kLfqYQh6lcLPAPgPAN5I5x4F8M5Syo+Y2aPL39+LxTcbn7/cvgyLD7l+2eCUjUCmFFgdZEpBESmF4+PjlVLwcxEpcMNiVXF6eho2TiUpdQ7W8uph1O7jfUS4rWeGkkP0bAtZWjKy5Ws1kqipCL7XTUAlK31zlevp6Ojo0kyEE8Pp6Wn6kdwsrzyQbVJGm6KLFEopv2ZmD8rphwF81fL4DQB+FQtSeBjAG8siZ+8ys2fY+ncbd4KIEGrqgUkjGnkjpcDmg/9m52PU6E5PT0MHX0QMANb8DjxSRHnk81HD4Pu4sbU6ag8pZOnJno3KpictEWoqoEYMNVLw45pi4JfkPO0XFxcrImD/kQ4CmoaoDKPXqbN899TF2PLdxKdwP3X0PwJw//L4WQA+Rvd9fHmuSgpjEt9CazTjisq+O+Cdv6YUIlJweZhVnHd+nbmojRTbyL+fbz2X7XtJQcPq/d2DjACicxkpZPfrp/4islX14PdEqsDviaavNW4tQ3VC9iiFbbSdrTgaSynFzAalxuR/HzaVmQPjXu1bRBBtPaQA4NLbetkrzDU53yvVayN11qkzDCGFLNyMgKIGXEtPdG0XpMBkwKsXtUNn6sFfooqIoRaWma1UpJKBHw9p89voH5uQwhO2NAvM7AEATy7PPw7gOXTfs5fn1lDofx8ODw9LrWFEDSmSgBEL87FWRkQI6jhiEqhd6yEFXUAVNRCWl0M7M5dRRArRctvsed5HYdbi0Wej31k8PffvghQ4/No3KKJRn+ufZ6Oidpalj8tQ23KrvjIiGKsaNiGFtwF4OYAfWe5/ic6/0szegoWD8S9Khz+hZ0TR85uAK0ynGHuUgpICp61GCu6YYmJwc6KnXHqUgjYyNVuGEIPGy9cyQojC4TTptV5yiNpB1tFbpMDh+CjNcl3XIngedSZCVScQ/zdHRAhR+aovieszw7b7Su+U5JuxcCp+tpl9HMC/wYIMfs7Mvg3ARwG8ZHn727GYjvwgFlOS39ITR69S2AYypdBLDJFy4HT6PhpplBDYqVhj/DFKISKEXZBCdH8rvCiclvnRIgXdD1EK3qG9E/rqV16Y5vfz2gUmFT/HZoROW2f17PWjC+FqA4aWhR7vVCmUUl6WXHpRcG8B8F1DExKZBWPQM2JkZoM7EnVjIojsS82DH/d0zJ6tt/xq6mFouNsmhVbYWXhjG3YrTgXPKGRKK+qwakqocuDnMkLWduQzGH6tVfbbxuRWNGaZjcgiGwn4/ogIlAx8ZoFnGE5OTnBycrKmDrQB1ORzKWVtmqr2PkZEEhpWrTN7Q+ZRhUlojFLQ8DUdfF6Ps5EwOtbws+d4NB6D1ggaDUoRmWtdqW9I42RVoWWUDS6+SpKJResyUwfbUNWTIIVaI+UOWLPJanZkixh0ytFJQacgI5WgEo8buL4xl5HDUMWgHVMbnDbmMaQQdaJeUoiQPdd6dkgcXg6R/6KFiNS080ckoasW+Xlvc5GJkSlaAKt1LX6N/6SGF+F5GjXsTTEJUgBy86GW2Uwh1MyH1vSjEkKkFDht2vF4y96Qiwih9T4Gx5eVnTbeaKVkRAqtkV3jbpGC1llGKjWMUQW1DpKFV1MtXmbsEI42dkRmbTHyQ0QKw+uQ7/M2w3nkOMYSYYbJkYKil/nGqgRdwqzmg65jjyoRQNgBWx/gGKoWespPiWYsKWyiFCJiH5KXsdiGUtDVitx5a/XGfoNsWXM0KEX3aTtzM9TTpXm8a5XCWPSYDTVyqBFF9BYksN5J/Lx2vIuLi7V37PVd+20SRDaq94ShHSkKcygpKDYhhch8bMXH17VTZnF4+DVCi1SiHntY2WIlXqwGxN/+0PiPjo7W7vd2xnnaBhk49o4UImbtuY8rqHfRkn87QX0IvHdElRuRQosYohG9pzNpBx1CKOqTyMK+ClKomY+RGonCikbSGmr2Paefj30qOcqTqwYlADch/NjVR6t+Tk9PV7/1fy+5DHrquweTJoWoY/fas/dFAAAgAElEQVTcozZXtBqN1yZEPgY/9jB4H3WG6Es9/EWezIzwY6/A7Jjjq1W4NrJaGJ6nno4TxVsbKXWfpbumULTMI6XA1yMC8Y4XxcVQ1RjlrTazk3U+dT56+2uVDf8+OjpaxccL4jjcWSlcoVKosTFwp6FE3+eLvuO3a6XQUgljlUIvKQx5Pqu3KF+bKIWe0TKyy6P8+d47e7SwKDMVItMhIgLNF5OCfxPjnlUKPdi1T0FHBSCe8oucij0f9xzqU/D4GdkI0xNGr0/hqkghql8PY4xPIbtXCcadir5p3nTKOZoN0DbGbUYHMu7YWRvzvb9sxcr2nlAKmrmaIogaVmZCRGSgaxN8CtKJoDXK8GjOZoB2+iGLl4Y4GGskMbTzZfdkYfai1SnHhLPLMHgkBi7/wYuqCD/mtsJtQYlFZ6/Uv8DmKserX3fyjYnKCa1Ffr3YC1Lg89GoViMEva7EoKsXvfIY0cjMU44ZKbTMhN5N08GNIUpjRCARvCwzconKYGgji56rjWoR2WfXtgUdrfkcH2eEwPfwJ+84TJ7J8valJOGv4Hs4/JxunE5XHEoMY8trEqTQ6sgKrsRMWWTn2UxwdcBKgacfs9FZR4WMDPR/HzYhhigtkT2r6Y7KzH9HeeT79Xk9HjMytfwXQ8PbBtjhpx/G0XR4J/Tn+Fn2L2k7YXXKz/oxv1THDmhf8hyZup4eVwqaF073EEyCFFpQmcZ7v673tXwJ0aKlXvMBwJpSyHwGrBK4gfSQBCMjBCaFFnlGyNSFXqudy8Bym481rTXyUdT8Htk9PfdFKqGFKC86evvUIdcvP6/vNyg5+TcfM6Wg9Rsphb0mhSFKIXs+eyYzHTKfQvaCS9QxM3NBzQa/f6w64HhbnZ3T2oMepTAW2xzphxDI2LB51AUu+xAYEbmxfe/H7hfwjs9E4OFwWJkfITMfmIS2gcmQwjagykCJoGca0l+AOj4+Xkk5HkXUSz2EuHaNTOL3HGfPD42v5/mplFeEnvqMyDlzbvv9wMKH0PPVLQ+DBzAfgGqkwCqX0zoUkyGFyBzoRWQqRIRQW4+gr0+7f4EdiZlpwueuC1kHnwop+Og51hm2TVVQg5qqUXr5unr+uV1oWXPb9DCUINgJye1UHdsadlaf6jTvQZMULP4jmH8H4B8CuA3gQwC+pZTy52b2IID3A/jA8vF3lVK+c2iisgbQ6nQ1YuhZqKQ+Bg+L/7SjpRQychhiHtTyp40ve35qpKD56AlzSPw1tPwMLZM1Gn2zvEeDBI/m+ql/vsa+BVUK7l9QYshIwcPclVL4GVz+I5h3AHhVKeXMzH4UwKuw+M8HAPhQKeWhIYnQQh6rFPR3zwKljBCYFHTkyOK7bqWw69E0Cz8jBCawaNSthdkb9y7B9a7p0PxwXnkP5G9Omq3/sbKSvpICqwUmAg9fF0OxqhmCJimU4I9gSim/TD/fBeCfDo55B4gKvaYSMp+COx6VzbnwM2fkdWOXSmEsKQD971hcN3QQqCEjCw9Hj3WAihSJKg0mBfUpRA5sTwObNkOxDZ/Ct2Lxn5KO55rZ/wHwSQA/UEr59eghk/99iBg2eW61r43Yar8NMSOcGFT+uV8hCr+mFqIOeC9iCNH03LdtgsnMgp501377sToZFd6mamohUwq85/Y5ZkZiI1Iws+8HcAbgTctTnwDwuaWUPzGzLwXwi2b2haWUT+qzRf73YZN0BOlKTQiehVCC0I+sOMPzQqVIKUxRMUwZUybGXvOm5z4lBndcZwOZrmfw85FPgdslL5BiX8KVKwUzewUWDsgXlWUuSim3ANxaHr/bzD4E4PMBPDYw7KrN3iO7eCRvzUJE5oOTAttxkac4UgqqMBwq78Zumne1Z1tlex3YhVLaJCwuh0jyD42jZkIpIdQ2ni2ITAiejfA9b/zC1NjBahQpmNnXAfhXAP5uKeUpOv85AP60lHJuZs/D4p+nP9wZ5tq+576W+ZApBd506kfNB161qCqjRgiM2XxYYNt537X54Od6n43CUqdf1GZ58NLZLW2f+h4N+xeUGHZGChb/EcyrANwA8I5lpD71+JUAfsjMTgFcAPjOUsqfDk7VFtBi5MzXwMRgZuHfirccRjP2Fz2koPWtarA2MHjH9QGH2xF3ao9HlW62urGmQoaiZ/Yh+iOY1yX3vhXAWwenAuufqgJiRRCZCct4Q4ndSwxc8P6C1MnJyUryZcuXXT0cHt7516daRYwxHxScZ5e7fG6K2AeVFJllCq9fNwey9ujhRSoBWH+7NWoz/KZu1D6VYPhtyp522MJkVjROAS1WVnWgJsSM/QaTl9an+hsyRZC1g0hd6MyBrpzlxUweRmQSb9vpPRlSiCqh916gf/FO5pNQG86XOetbamN8CjPWsSvFoMppCKKR3cPke/R+v6dV/6psOYzojVnPi/oieghh03Y4GVK4arQcQdH0Zc2nMEUyUAdn5PDcRNpHMyvZ731BbXDpneXh66wwWiZGRAoa7lW0w70ihRoTZpU5xH7n5zNHpCqGXauFHl9DdK3nd7TnMKO0ZL97rm1CQD1lyn4Wfq7VmXt8OZzu6D5VKK3jGjkMaZM9/rKhmAQp9CReCzaSY35cq9yMnTPFUGPnyK8QOZ6iPW+1Tp5hDAlMhRTGoOfZyHzg3z1hjCEFDj8jg+xc1h7dn9DbJrc5OE2CFK4DrdEhK/yWX2EK6FUO0Z7DiMLNfvc8fzeBO2sGHQxqBNWjFDysXfu19ooUtm0+RJ9D47hUEUQqYdfk0NNQeuTnFEhhE6KYmvkQPZep2ZZS4fZodvlfozRMXVXbIomh2CtS2AYycqg1iJZjZ2pKYcZ41Ew+RQ9ha7jbStdd71OoFSaQ+xOGZDoaNWsfT43iU/MhSkNvmiLfwxC0GiHHwaNY5MMYi8yWjkbsqaHVeSMyiEZ8HVz8Pl6M52XRUiwZ2FfivobWCtu9J4UWMns/+63PZXJPiSGSgzWZVquAHvZu5aHXzozKh89HknobqIWvRDE0zG3fq1AS03OZQtCyZTLwpcq8j9JZM62yutS01Uhg00V1kyGFIUqBj4coBd+3PrMexT+EGGalsN9Kodbe/FnPH88U8KvKTAxaHmOUgu89jNZ6hU3WLUyGFIZgGx2JyUE/xZ45d3a9vHTG9SNTBgpuI2w28P08rbiNdHH4vQvq7hlSGIKWyZD9tVvN+9tjGlwXMll8nebDlBVDhsx8yEyBzM8QtaGx6Rlint4VpJDZUhlaGa6RgR9nb0DyjITG1zM3HPkNWj6FnvJp+Rayzn/d5kOrY10VejtnVHf+POeLf0fkoNfGknNkwtwTpKBQ5gUuSyg+x/dGbK5vo2Wk0DMTwRKNkdmjUcVkDU/z3JKf2uD2QSlcpZrK8h2lKSNz3reIgY/5HYasfmpblD5N6y5IoflPEWb2ejN70szeR+d+0MweN7P3LrcX07VXmdkHzewDZva1vQmpFUiSrlFKgVWC78/Ozi79GWyNEKasFLIy2qSRZKiFH5XHtuMfit72ldUdn/PwNNzabNaQNETp4bSM2Xox9n8fAOAnSyk/Lon/AgAvBfCFAP46gF8xs88vpZzjmtDrT8j+/3H2KeS4230KEeFlPgU9lxH42LK/CjJwNJVCKeXXAPR+Uu1hAG8ppdwqpfwhgA8CeOHgVI1ES45FU5BjiWFqqKmIqCFvY6uFz/HsC1pqtab6th2//x6LTchh+B/N3cErzey3lubFZy7PPQvAx+iejy/PXYKZPWJmj5nZY9tuOJmsY2Jo/VN0jRiW6d+oUUTSdNvYVLZuEr6SxtTJISKySF1FdbVJ/WX1sst6a2EsKbwGwOcBeAiL/3p49dAASimvLaW8oJTygiGFqp0oG8F4HzkZmRzcpxARQ49SGCvpMluR85blcdOR/DqVwi4lcC2dtftq6c58DFHaxpahPsvpya4PLctejCKFUsoTpZTzUsoFgJ/GHRPhcQDPoVufvTx3pciUQjQdGa1VaJkQwKwUWuHPSqE/3rtCKZjZA/TzGwH4zMTbALzUzG6Y2XOx+N+H/71ZEvvRw8w9PgU+36MUpoB9UgpTRUth3Cs+hbH/+/BVZvYQgALgIwC+AwBKKb9jZj8H4Hex+Du57yqdMw/ZyyMO7tSeQX0TTe9VIqj5EdiMOD09XR1HYWVEEX26TfPkz2YmiC+N9XN+rx97GoD1T4XXym7GZfR2Eq3zlmospay1AV16zHFrp219bzFqR0PIuxdb/d+H5f0/DOCHhyaEC0qZsjbqc2VEz2QOxpZ/4fT0FKenp5yvtXCj9GvF6tp37uDRsxwGx8V5dCLwxsfhczlcJ5jMrhvqt2ndFw0uWefU+vR6630XQdtMzRfgcXnctZf6dBuKSaxo1I6gex4lM/mqxFAzGWp+BCcGJwVtLBp2xvY+SigpMJFFDYTLguM7OFj8MQ2fj5RCqyNqo+cO3CKUIaNrL0Flpkfrviw9Y89lPoOe0TYb6XWv4UcEEBFIVJ7XqhSuCt4RuKFHBKHmAxOG3xOphSFKwQnh7OxsLR4lJ0emEiJS8FdqtXF4xbP5EJUBn49GsikrhetIW6YUMoLLyF/zo51cB4Ooo2fxZaSi6fHfQwhhr0khKwRHLdNRgUf31SQWmw5MDN5JvbI4vVmFsi2ZqYoo/3w+Uk5ZWFMggn1H1v647UTqzvdRp47MgCje2qbI2sNdSQq1zPL1Vhg9W0QImWkBrFc6gDVHYvbXcmw+qMmQ2Yyaj6hcHK3Gxs/OxNGP3vLOOm+vuRGFUdu0TWgb3iYpbLKicS/QSw61pc4OM0v/wl7P1bzIY/Og6BmJZgxDb0caWuY9RNGjFnapEByTUQo96CmEXnlVMyN4YxtfpxuZEHr+a1LBo0BNMWj+snAj+5Of4XNXDU+DNtZtpifLY+13Zq624omUg6MWltZ3FmamJrn9zubDSPOhdq2HGA4PD9c6YkYM/rf00VQU0K70FhloGXC4SgJ6/2w+DEfNfFBS6SGEqJ5q4bXMhx4CmM2HBD0kEDka+X0Ifz4jhdbf1g8hh5pkVMzmw/bRU9b8e0i4NXDbqtVrz7qEu8Z8iFjQf0fyaeh2cbH+1V1WBEoEp6enuH37Nk5PT3F4eFglhqOjo9V2fn6+to/mrT0dPDsRlcGYPM/YLtQ0GELirfB4UzLI1ipkg9tdaz5sgrEkERGDT0X65p1cHY5eeUwMbkLwdn5+fqkBODH4MmjNR49JMZPB1aBH2o8Nd4xi7FEIdw0pZCOm76PM9dpZEcPqCsbz8/M1MnClcHx8vEYKSgiqFlr+hWj9guanZh/2VHytoW5iZrRGwE2hCmloHJHTL3s2C8/jzcyFmmrgZzUPft2ntaPnW+aDt+Hsm6IZOQzFJEgh69z+O5PSfi66xkTAy4PNbE0VeCUcHx+vNp5R8Gs3btxYEcPBwQGOjo5W4fl9itu3b18iIgArheCVzunrKRd+n4PLYMbm4E5fW4SkCoKR1YcODC1/FJMNkwGvuNXvgChh7C0pAPly3iHPDTEdsncdXCXcunULt27dwo0bN1YFz4XsZODHrDh84/ULLcnZKyWzhjmm7GbcQaQuWvWQPdsTRu/qx8zcbX0+cO+VgqInQ5FUG2tCqIORN2dkJgUdRfxlJSUFZn6tbB8BWAltQgocTg0RkbD0HfKs1oX+jsKsEVkkwbM4svTUTIee0b2nLrK4OewsnOj9mIwchhJCZkIMxSRJYVP0kENLKdRIAbjzl2C+jyooUgotDCWFWR1sF2NIoZdQmRhqvxU1fxgv02fTciwhAH0fWXk9gG8A8GQp5YuW534WwN9c3vIMAH9eSnnIzB4E8H4AH1hee1cp5Tt7ErKp+eDHNYXgFaBrE8zsklJw8yFTClyZAEIGH2s+MOHoiziz+bAbaJlGU4TRfQpVPlnnjxRCNHhkaoFVaaQQNlmvMOp/H0op/4wy/moAf0H3f6iU8tDglGwZQ8yHg4ODS0rh+Ph4TTGwU8edRFy5x8fHaxUDACcnJ+HUZib1M4bvJQUPY8Zm6FF0tWejLXMuRgvcHF6XNdMhMyF2qhRKKb+2VABRARiAlwD4+6Ni3zK4U3kB1xyN7gtgpcCkcOvWrdDH4AuTzO68IMUV4Y3g5s2bawpE72G7MbPLoxHMr5vZJdk41KTw+3V0utdMk0gJtNSdPgusv5tS8x/o27QaD5d99CGgFhmMVd7A5j6FvwPgiVLKH9C555rZ/wHwSQA/UEr59aGBtuQ1o9d8yJSCh+dK4Pbt26v1Bjdu3Aj9C04GwJ3pSU6HV/bNmzfXiIYr1zt3Ld2adw6f72ETo+VwjMpPCSALp7eB9aRjG8jaSfY7O+ZzESm04ozC0OlHJYLaC3RAvIJxXxyNLwPwZvr9CQCfW0r5EzP7UgC/aGZfWEr5pD5oZo8AeGR5vGEyLqOHGHi1oY/oR0dHK2JgpcDmhb8kBVxes+CEcXx8vCKF27dv4+TkZGV+ZOsaes2H6L6r6IT3CrZlPmREwFvmSwAumw9KDnq8jYVLwAakYGZHAP4JgC+lTNwCcGt5/G4z+xCAzwfwmD5fSnktgNcCwOHh4VZ0aiSdnASWaV7tfXTlBUVOCr5K0R2Oqhbcf+AVenR0tNYIjo6OcHFxgZs3b64Iwf0LumiqRl6cZn5PQhUC53U2H8Yh8wUMNR+GmA6sJjie2iCWqYTM4XjVSuEfAPi9UsrHqUA+B8CfllLOzex5WPzvw4c3iKMbUYeqdThdRRi9EOUzEE8//TT+6q/+Cp/61KdwcnKyesbJ4/j4eBWumwUHBwc4OTnBjRs3VorBX6zimQ9mfE53rRGqQlBsaj5MEVNVQZFp12susAkJrJM9d+6Wk/HKFy9Z8L8PpZTXYfHv0m+W278SwA+Z2SmACwDfWUrp/XPawVA7uHVvphwArK1XcNVw+/ZtPP3003jqqadw48YNHB8fXzIdnBg4PGd/JgXu9Mru7qdQBRB1WCaOyMu8DaUwRfSS31ifQq8qyMJiRTfUf8D5U7+Xt4/olf4en8IYjP3fB5RSXhGceyuAt45KSQDuZBTHJWkdKYPa74gU/CUmlvfHx8crlXBycrI26+C+g6OjI5ycnISNwd+ZODs7S1dSsrOTTYCokdaUDz/XU6Z3A7ZNCrqPTKoojJofobV6UU1CNRcys4FVZs3JeNXmw7WDyaFlPgB3Ph/Pi4JY9jsLe8W5CfHUU09dWojknf7k5GRtxoIbBDsXmZBYlbBKcKnI045ZvnkqUjGbD5vFMUQpZIRQUwrsRwAuD2rZ6sUhaxR2vXhp8hijFNSb7xXlKsFJ4emnn17zFANYqQg3D+67775VGH4fKwUmJSYEd1xyQ2itflQzSCv9XlIKEbalFHrjyhRC62tckVJQlaDv5tTMh6k4Gq8NtRG0hxQcTA5aCWa2mpZkhQAgfNHp5s2buHHjxpq54HsmHf4GgxOLqgiv2CzPkQ+gtzHPpFC/LzMPfB9tPTMMkRkYjfA1U6HmQ8icjHc9KWS+BL7eQwpqt/tvrwCvyNPTU9y6dWstPh/NdVnqfffdh5s3b+K+++5bmQtuHrAPg30R/v0GlnzcOKK8ato570MdZHcjdkkKXOdsAqj/oGYqAPnCpEghqFLIyEHbz11BCjoSRtczMvBzNXPB/QjAZY87Mz4rBf4vSeCOmohkvZsC/H4DV56qBfdBZKQQNSLNE0Pz1CrjGnrC4vB6fRKbEFIU/q4djbrvUQj8/x+16Uevvx5n4lCTYeezD1NCTSnUSIHvZaXA4bmDzwnBK92fubi4WL0YpWm4uLhYUwXaoZiMdHaCn+EK1nz7PewkHaoUIjK7Smw77qsmBTUFspmGHv+B71vq4Pz8/NJXliJCuOdnH7Rw/biXFPRZR2QDsnPQ1y8A6zMeXEl+zdVApEZaSoFJQRVENMft4bcwk8J2lAKbBZlSiPwKwHqbjKaoI1IYujbhniQFRVYQNVKIwtBCZrveK9VfmvJZiYODgzVi4NmFGzdurDWM8/Pz1bJpnqr0OJgwMrmsjdQJpKcRzKTQRwpazr5XH0Gvg5HB9ZTNMESk0LNy8Z4mhVYH732ef/vIr8TAagHAatry6aefXlW42oX+4tR999239i6FmxlqagCXlYSmUR1WTArqbMrQSwpqXk0BuyQzLhc3GTOlwB0+Mhl8Slo3YN0flJkOmTrw9sJL5bdNBo7JkIKaAtGxo8a+Q5SCXo8kmfsbOO7bt2+v0uAdnSuSX5f2lZDHx8cAsMb8us4gIoSogTFBqI3padoETghXMbL3YteORmD9a0uZUtBZhZ4pSM0Ht7VNlELLoTgrhZHPs+NRPbhMBg4zW/kVnBBu3boVfvz1/Px89YbkjRs31uJQUohUQkYIfs33nM5aZ56VQh62km3NfGiZDpGZx20tWqDEZmcPKdwTSmETDFUKESlohblKyOLzyrp9+/bqn6DOz8/XXrMupawWNbmjspYe4I5aYEQy1Pfa0aO88XlgcyUxFlfhzxijFDLy1c4dORWj8zUlGxFCtg4hW848xJ+wt0qhZgtvOlq1OiGAS52KVYJW6Pn5nU+387HbolzpZoZbt27h5OQEN2/eDO1NjlfjiswIbpDsZOR7sobj6fJpzRqZ9pR9zeSLrrVIgVXOpvWe+QT4euQvyHwCkfmg93LeWYFy2aufQKcbI2LonXq8q0gBWJ/LjySwdhBtaJE0jhoZx8Ph+T1egewz8E7EswhMBj6yc8W7ieGk8PTTT69emKp9sDNqXHzNG2cpZU1RcKONGow6Trmx8j21OlD0kEKrLhlRvQ5p1BkRRG0kUgG9eyYFjVvLHFgfKGqk0LucWes3moHahFQnQwq9oxODG2/UmHrs4ozpveC9E6k9qSvX/Bn2K5RSVt9huHHjxtr/TfqMRPafky2lwKTg5zMVwH4MDotJwvOYlV1GXFH9RSNlDyISj0yjrB513zIHWkogMxH8fjcHI0LkmQLv4JEaiHwI0QKliOAjhZepviHo+cjKc7D4vPv9AAqA15ZSfsrMngngZwE8COAjAF5SSvkzW5T6TwF4MYCnALyilPKeWhw6SiXpWLtfR7NMKWRhZSMYp4Xj5fCjhSpe6cfHxyvn4/n5+YoU/OUn/s9K36K36Tg9HD83Rj/vZODpiLzTrA44LM5rTSmMJYUxZoTWSS9apgKP+HpvNKOgU476vJMzlzUQf0QnI4Vs6rG19RDALs2HMwDfU0p5j5l9BoB3m9k7ALwCwDtLKT9iZo8CeBTA9wL4eiw+w/Z8AF8G4DXLfRW1DqzXe+VtLfyMQLjzRPerTFdS4K83lVJWn4t3UnBi8GOfslQVoWnTRs7z6WoKRHvOl/s7IiLNykvLQO/hhnkdjsyaCtCOnKmEiBSyl5v8WP1PmSMx2mfHSio9fgSP/0rMh1LKJ7D4SjNKKX9pZu8H8CwAD2PxmTYAeAOAX8WCFB4G8MaySNW7zOwZZvbAMpwmhkpOhjf8qHHob20QURr8mZ508SjtjcT9CtpYdD0DE4IrB00bj0qeFiYmHS1UTbHvgtPKPpPaCKSkFJVDrTFyebbu0XxEz2VKQH8PIQUvm8hciNqIqrJsmrGHFPhZJYWeqUgu/52bDwwzexDAFwP4DQD3U0f/IyzMC2BBGB+jxz6+PNdFCkPRk2ntILo5tGHxXo/5HI+OvGbAP6ASzUX7X967knBC4C84qXyN4may0Lz65p0+IgU3PXjdhJoem4w6ml4t8yzslrLjcxnZ95KCl4nvVTlkiorJIFIH0YKkbIYhcjBOnhTM7NOx+P7id5dSPikVW8xsUOxG//uwDMPPXxqZ+PdYEqiZG2xLt0hBO5z6QjiM09PT1Uh8dna25mB0E8NNC/6+gjoi/b6osWcNg4+VGCKV4MTgeWKyy1SIxsHlr6omKp9afXJ74PLXuuDjlmlQI4WMHLSstRxUJbDvoEcpMBHUvrs41nzYGSmY2TEWhPCmUsrPL08/YUuzwMweAPDk8vzjAJ5Djz97eW4Nhf73gQllE/MhQ0spRA22RgoMVQocJ4A1J6B/wIVnHSJSiEgCQPWV3EghcDr4Hp6N8N8cFjdwvj/Kn57rMR9YivfWc1RPei7r/BlZZGFyetl3E5VnNKpHSqGlEiLzQcPOCOHKScEWpfE6AO8vpfwEXXobgJcD+JHl/pfo/CvN7C1YOBj/onT6E8aiRiRKCDUTYggpaAdUYtBR0kdiM1utbnSicHOCGxD/Ya03CFYOmkeOM1NFZrY2hepp887PZgUriiivQxpoVt6c9gxZ3QxRBD2kEMXH9az12nIoDiEFDSsihaxsa+VYI+kaepTClwP4JgC/bWbvXZ77PizI4OfM7NsAfBSLP5oFgLdjMR35QSymJL+lJyFZ5fRirLLgDpSRgqaltzNEIzCvaeCOFzki9VinLv17DTXiU/A5JQcnLV4r0XJAZg1VG6SSK9dZre5apBB1+Ej663MR6evvKG/aaSMS0AVJtSXM6jNgVRCVfauss3Y5BD2zD/8LQNZDXxTcXwB81+CUbBG9BZGNqK37eklBn/WOxo1WRwl3NKqk9GsRKfSMon6N79H8qTrgxh/lm8u6tY/q5apIoVYOLXBetRNnqiAjBa3PyInIfh0mhlqZZoQwFpNZ0dhSClEF9kimrCFEI1etA+mow/F7nNG0FR9HedDVkd7xo0VO6oDU/5kws7WwPL21eXbOQzTF5secz6zcM0Rhavll4UR10zINePq1pgqytGqa/Xc0lcjfx9C9qgRVA6rEIt+B+nMiQqiRwq7Mh71GJK03DS/b1KegzzFYQjuhaEPgjpQpBV1uHX04NDqObGVOl5KG5l/zUYOSQo1kaqTg6PUX+HOtNKoayNKcfeuAycCPVUVEjsOWEtvGqD8GkyGFMUphKLZRuDUi8I4WqYaeMF22e1gcnjemjAD8mNc41O7L0peZQZmyivZ6rCMik/7G/AsAAAgQSURBVJ5fj+LPwmQfga4jYFLIRsvot6fp7OxsNWqrjI9IQVUBv8sQORNVMUUjvWIbg9kQTIIUIjavkUDtWqQIogZWe74WV00Z8OiaxZmZQRomj1hMCGwKaGevbX7f8fHxpSnNLJ+a5pZ5pecdSgaRRNayiJCZdDWSyghBO6KXs7/IxqTQUgq9DsXILIukvrYfbdMts2vTAXQSpLBviEY5Hp3Uq+/XFawEuHPwb5/K1I7M/gI1K6JZCr/v4uJidb7VubLjTK5rOH5vzXyIOkZEqtzoo9mEnjqLwmcV5iO/SvyWUogWKqlDskaKV20etDAZUtiFuaAYU/jZMy71eaUgE4NKW27k0ajsBOBhsTlR67xKCtGx710as3pQgmmpAZbwnMfaSsGa+cC/vSyijpIpF91Ho2fUAfm3LkHP1gtkSkHXKkR+A01DjRAV96T5sE/QyvG5/azDZp0pGlFZXWR2sv/mOLxh69eg/NgXS/HKyOjtv9YiH76HJS3vOb2cr0gJqZzWa1ruqh50r89FHTHqkNyp/ZX3bBERkwITBU9RtvwHU1QHjJkUOqCjlFdqzY7uIQWXwZGy6CUFAKvl09x4lSD8tyqFGinUlETrxaFo9G51zmxEz+ogUpPRyBvF0SIFJQQnAJ2a7FlnkJFBpl6ifN+TSqEn0z0mRa3BZGFlndrTFdm1WZo5jKiTR2aHjra1TdPLjdzszgdX1MHoioF9CjVSiAih594sjZG0j5RCzflWQ9axaiYLX/MO7l/hjkghWlAW3RMRUJS2KJ+9eex9ZgwmQwpTBsvWTNpGqMnxTIr3vrzD+8j3oB3ffw8hBb2mW0QKjhrRepm1lEI2iqr64HqJSCGS8Bkp8J8Et4gh8pP4rFEtL9pmZqWwx6hVnl4HYlJgInAS8L0/O4QUIkXkpMAd2H87KWSjf2YiZN+SbJECp5O3jBQyuZ11qmjkzTq/KgclBZ+SzAgh2qL4WiZBlv6pYCaFAcgqbkiF6igGrJsqLaWgJBDFzfdpo/SRMOvckXKISCEiuhopcLqikX3XpKAjuhKFy35dfahhtGYUetpCjyK455VCb2EOCU8Rjahjw9TwI/9Da5RX2evXVCnUSKIGJRw+FzkHI8dhzXyokQKXA6fhOkghUgURKUT31QhF06lpbCkFvcZ+h2gfoUd5jOlXkyAFIPYu+/G2w+d4xjwXpTWT9lEn5s7jYL8AcKfjethRR6yBScEbH6ctI5tsVoHXNWRpycozKpusM7PTcZtKISKAFpH0Ps9panXGKL3Zb95HZVsrj1oaWpgMKTC4AY/J2C6UQi0tEREAdzq23sNhsWLQ69wBSylrnfLi4iIlBr+XiYbjqamYjBRUOdRIIVNS10EKNVWgHZFRUwUZIWR1MSSttRFfy7GGWSlcAbQRaLpqSiG638PkvV5TpcDhuIMygyoPP2YFkaU5MysyUogIL6rDHlKodZJtkoJuXK5efq1nauXfIolaGqP83fNKYcb+o7fTDO1sM3aP/vd7Z8yYcU9gKkrhjy8uLj4F4I+vOyEb4LOx3+kH9j8P+55+YLd5+Bs9N9lUpJqZPVZKecF1p2Ms9j39wP7nYd/TD0wjD7P5MGPGjDXMpDBjxow1TIkUXnvdCdgQ+55+YP/zsO/pByaQh8n4FGbMmDENTEkpzJgxYwK4dlIws68zsw+Y2QfN7NHrTk8vzOwjZvbbZvZeM3tsee6ZZvYOM/uD5f4zrzudDDN7vZk9aWbvo3Nhmm2Bf7+sl98ysy+5vpSv0hql/wfN7PFlPbzXzF5M1161TP8HzOxrryfVd2BmzzGz/2lmv2tmv2Nm/2J5flp10LPMdFcbgEMAHwLwPAAnAP4vgC+4zjQNSPtHAHy2nPsxAI8ujx8F8KPXnU5J31cC+BIA72ulGYv/A/1vAAzA3wbwGxNN/w8C+JfBvV+wbE83ADx32c4Orzn9DwD4kuXxZwD4/WU6J1UH160UXgjgg6WUD5dSbgN4C4CHrzlNm+BhAG9YHr8BwD++xrRcQinl1wD8qZzO0vwwgDeWBd4F4Blm9sDVpDRGkv4MDwN4SynlVinlD7H4w+MX7ixxHSilfKKU8p7l8V8CeD+AZ2FidXDdpPAsAB+j3x9fntsHFAC/bGbvNrNHlufuL6V8Ynn8RwDuv56kDUKW5n2qm1cu5fXryWSbdPrN7EEAXwzgNzCxOrhuUthnfEUp5UsAfD2A7zKzr+SLZaH/9mpqZx/TDOA1AD4PwEMAPgHg1debnDbM7NMBvBXAd5dSPsnXplAH100KjwN4Dv1+9vLc5FFKeXy5fxLAL2AhTZ9webfcP3l9KexGlua9qJtSyhOllPNSygWAn8YdE2GS6TezYywI4U2llJ9fnp5UHVw3KfwmgOeb2XPN7ATASwG87ZrT1ISZfZqZfYYfA/gaAO/DIu0vX972cgC/dD0pHIQszW8D8M1LD/jfBvAXJHEnA7GxvxGLegAW6X+pmd0ws+cCeD6A/33V6WPY4qMIrwPw/lLKT9CladXBdXpjycP6+1h4h7//utPTmebnYeHZ/r8AfsfTDeCzALwTwB8A+BUAz7zutEq634yFxD7Fwj79tizNWHi8/+OyXn4bwAsmmv7/vEzfb2HRiR6g+79/mf4PAPj6CaT/K7AwDX4LwHuX24unVgfzisYZM2as4brNhxkzZkwMMynMmDFjDTMpzJgxYw0zKcyYMWMNMynMmDFjDTMpzJgxYw0zKcyYMWMNMynMmDFjDf8faUs0cTxQx18AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_id = 3\n",
    "sample_img, _ = image_datasets['train'][sample_id]\n",
    "sample_img = transforms.ToPILImage('RGB')(sample_img) # Tensor を画像に変換（もとに戻す）\n",
    "plt.figure()\n",
    "plt.imshow(sample_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を表示しやすいように、標準化をコメントアウトしていたので、戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    # training data用。必要ならaugmentation(Flipや切り出し)を行う\n",
    "    # 今は、特段の加工は行わない。\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # validation用。通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # test用。こちらもFlip等は実施しない\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2節と同様、バッチごとの読み込み用の設定をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バッチサイズ分のデータを読み込む。\n",
    "# training はデータをシャッフルし、読み込み始める画像をランダムにする。\n",
    "# 他はシャッフルの必要なし。\n",
    "batch_size=64\n",
    "workers=0\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        image_datasets['train'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=workers),\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "        image_datasets['val'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers),\n",
    "    'test': torch.utils.data.DataLoader(\n",
    "        image_datasets['test'],\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=workers)\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークアーキテクチャ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像解析で広く使われるResNetなどの固定したアーキテクチャもありますが、ここでは汎用性に重きをおいて、シンプルなCNNの記載からスタートします。\n",
    "\n",
    "ここでは、\n",
    "```入力画像 -> Conv2D -> ReLU -> MaxPooling -> Conv2D -> ReLU -> MaxPooling -> Linear -> ReLU -> Linear ```\n",
    "という形のネットワークを組みます。\n",
    "\n",
    "ToDO: ConvolutionやPoolingが何であるかの説明。図が必要？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3, padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3, padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, 120) # channel_num * x * y\n",
    "        self.fc2 = nn.Linear(120, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ** convolution layers **\n",
    "        # 224 x 224 -> 112 x 112 \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # 112 x 112 -> 56 x 56\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # convert to 1-dim\n",
    "        x = x.view(-1, 16 * 56 * 56) # channel_num * x * y\n",
    "        # ** classification layers **\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv1とconv2が、2次元（＝画像）のコンボリューションを実施する層になっています。poolはプーリング層、fc1とfc2は全結合層です。\n",
    "* nn.Conv2d(3, 6, 5, padding=(2,2)): 3チャンネル(=RGB)の入力を、6チャネルに拡張。\n",
    "* nn.MaxPool2d(2, 2): 2x2のマス目でMaxPooling を実施。\n",
    "* ... \n",
    "と、利用する層の種類を定義しています。\n",
    "\n",
    "上記の関数で定義した層を、どのように組み合わせるのか表したものが、forward 関数です。こちらでは、活性化関数としてReLUを利用して、\n",
    "* x = self.pool(F.relu(self.conv1(x))): 入力画像 -> Conv2D (conv1) -> ReLU -> MaxPooling (pool)\n",
    "* x = self.pool(F.relu(self.conv2(x))): -> Conv2D (conv2) -> ReLU -> MaxPooling (pool)\n",
    "* x.view(-1, 16 * 56 * 56): 平滑化\n",
    "* x = F.relu(self.fc1(x)): -> Linear -> ReLU\n",
    "* x = self.fc2(x): 最後のclassification層\n",
    "\n",
    "という形で、ネットワークの構成を順番に記載しています。\n",
    "\n",
    "前節同様に、作成したネットワークは、指定するデバイスに転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "model = Net()\n",
    "model = model.to(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ステップの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ステップの詳細を定義します。現在までに、ネットワークアーキテクチャの変更と、バッチごとのデータ取得を画像を取得するよう変更しましたが、この学習ステップは、前節と全く同じ関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test_accuracy(model, criterion, optimizer, phase):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train(False)\n",
    "\n",
    "    for inputs, labels in dataloaders[phase]:\n",
    "        labels = labels.float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # 訓練のときだけ履歴を保持する\n",
    "        with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(inputs)\n",
    "            _, classnums = torch.max(labels, 1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, classnums)\n",
    "\n",
    "        # 統計情報\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "    # サンプル数で割って平均を求める\n",
    "    epoch_loss = running_loss / dataset_sizes[phase]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    print('On Test:\\tLoss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    # 途中経過でモデル保存するための初期化\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    # 時間計測用\n",
    "    end = time.time()\n",
    "\n",
    "    print(model)\n",
    "    print()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch:{}/{}'.format(epoch, num_epochs - 1), end=\"\")\n",
    "\n",
    "        # 各エポックで訓練+バリデーションを実行\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                labels = labels.float()\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 訓練のときだけ履歴を保持する\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, classnums = torch.max(labels, 1)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, classnums)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 統計情報\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == classnums)\n",
    "\n",
    "            # サンプル数で割って平均を求める\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('\\t{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}'.format(phase, epoch_loss, epoch_acc, time.time()-end), end=\"\")\n",
    "\n",
    "            # 精度が改善したらモデルを保存する\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            end = time.time()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print()\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深層学習の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行も、前節と同様です。つまり、深層学習を用いて画像の分類をする場合には、一見長く見えるプログラムの部分は変更の必要は無く、モデルやデータの読み込みを変更すればよいとわかります。\n",
    "\n",
    "各エポック、１０秒以上かかりますので、表示が出なくても焦らずに待ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/19\ttrain Loss: 1.3789 Acc: 0.3230 Time: 5.8349\tval Loss: 1.3869 Acc: 0.2763 Time: 1.3818\n",
      "Epoch:1/19\ttrain Loss: 1.3678 Acc: 0.3230 Time: 6.9394\tval Loss: 1.3816 Acc: 0.2763 Time: 1.2974\n",
      "Epoch:2/19\ttrain Loss: 1.3544 Acc: 0.3230 Time: 6.9987\tval Loss: 1.3663 Acc: 0.2895 Time: 1.6280\n",
      "Epoch:3/19\ttrain Loss: 1.3313 Acc: 0.3230 Time: 6.6011\tval Loss: 1.3276 Acc: 0.3421 Time: 1.2551\n",
      "Epoch:4/19\ttrain Loss: 1.2494 Acc: 0.5088 Time: 7.2086\tval Loss: 1.2242 Acc: 0.4605 Time: 1.4410\n",
      "Epoch:5/19\ttrain Loss: 1.0543 Acc: 0.5885 Time: 7.2794\tval Loss: 1.0306 Acc: 0.5526 Time: 1.2671\n",
      "Epoch:6/19\ttrain Loss: 0.7629 Acc: 0.6858 Time: 6.7414\tval Loss: 1.0360 Acc: 0.5132 Time: 1.4577\n",
      "Epoch:7/19\ttrain Loss: 0.8602 Acc: 0.6814 Time: 7.1610\tval Loss: 1.1687 Acc: 0.5526 Time: 1.5025\n",
      "Epoch:8/19\ttrain Loss: 0.6563 Acc: 0.7257 Time: 7.4276\tval Loss: 1.0829 Acc: 0.5658 Time: 1.5157\n",
      "Epoch:9/19\ttrain Loss: 0.5797 Acc: 0.7168 Time: 7.2624\tval Loss: 1.0014 Acc: 0.5526 Time: 1.3646\n",
      "Epoch:10/19\ttrain Loss: 0.4962 Acc: 0.7566 Time: 6.4973\tval Loss: 1.1075 Acc: 0.5395 Time: 1.3362\n",
      "Epoch:11/19\ttrain Loss: 0.4486 Acc: 0.8009 Time: 6.0174\tval Loss: 1.0782 Acc: 0.5658 Time: 1.2245\n",
      "Epoch:12/19\ttrain Loss: 0.3794 Acc: 0.8540 Time: 6.1390\tval Loss: 1.1054 Acc: 0.5789 Time: 1.3203\n",
      "Epoch:13/19\ttrain Loss: 0.3449 Acc: 0.8673 Time: 7.2116\tval Loss: 1.2978 Acc: 0.5789 Time: 1.3189\n",
      "Epoch:14/19\ttrain Loss: 0.3220 Acc: 0.8761 Time: 6.6440\tval Loss: 1.3212 Acc: 0.5789 Time: 1.3071\n",
      "Epoch:15/19\ttrain Loss: 0.3129 Acc: 0.8805 Time: 7.5925\tval Loss: 1.4809 Acc: 0.5921 Time: 1.4606\n",
      "Epoch:16/19\ttrain Loss: 0.2777 Acc: 0.9027 Time: 7.0582\tval Loss: 1.3826 Acc: 0.6184 Time: 1.3097\n",
      "Epoch:17/19\ttrain Loss: 0.2435 Acc: 0.8982 Time: 6.3025\tval Loss: 1.4737 Acc: 0.6053 Time: 1.4749\n",
      "Epoch:18/19\ttrain Loss: 0.1908 Acc: 0.9248 Time: 7.0017\tval Loss: 1.6340 Acc: 0.5921 Time: 1.5498\n",
      "Epoch:19/19\ttrain Loss: 0.1665 Acc: 0.9381 Time: 6.8870\tval Loss: 1.7496 Acc: 0.5921 Time: 1.4005\n",
      "\n",
      "Training complete in 2m 45s\n",
      "Best val acc: 0.6184\n",
      "On Test:\tLoss: 1.7826 Acc: 0.4474\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "# モデルの初期化\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "# 損失関数、\n",
    "# パラメータの最適化方法、学習率の更新方法を定義。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "\n",
    "# 実際の学習を実施\n",
    "# 結果出力用ファイルのprefix\n",
    "#outpath = os.path.join(outdir, \"cnn_b%d_lr%f_m%f_e%d\" % (batch_size, lr, momentum, epochs))\n",
    "#model = train_model(model, criterion, optimizer, exp_lr_scheduler, outpath, num_epochs=epochs)\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
    "# 学習が終わったら、結果を保存する。\n",
    "torch.save(model.state_dict(), 'model.pkl')\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私が実験した範囲では、強い初期値依存性があるので、何度か繰り返してみて、結果を確認してみてください。\n",
    "\n",
    "多くのケースで、train Accが0.8を超えるなど、訓練データでの精度が高い一方で、バリデーションデータやテストデータでは、Accが0.5程度と低い値となります。この様な状態は、過学習(overfit)である可能性が高いです。深層学習では、このようなシンプルなモデルでもパラメータ数がデータ数に比べて極端に多いので、頻繁に過学習が起こります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation (水増し)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "過学習を避ける一つの方法として、画像の水増しがあります。ここでは、データ読み込み時に水増しをしてみましょう。\n",
    "RandomHorizontalFlip()で左右反転、RandomRotationで回転を行い、向き依存性を解消すると同時に、サンプル画像の数を増やします。\n",
    "\n",
    "データの水増しは訓練データに足してのみ実施すればよく、バリデーションやテストフェーズでは、水増しを行う必要はありません（これらの画像の精度を判断したいので）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "\n",
      "Epoch:0/19\ttrain Loss: 1.3790 Acc: 0.2788 Time: 7.0610\tval Loss: 1.4270 Acc: 0.2763 Time: 1.2823\n",
      "Epoch:1/19\ttrain Loss: 1.3592 Acc: 0.3230 Time: 6.3087\tval Loss: 1.3900 Acc: 0.2763 Time: 1.2905\n",
      "Epoch:2/19\ttrain Loss: 1.3214 Acc: 0.3584 Time: 7.8437\tval Loss: 1.2785 Acc: 0.3947 Time: 2.0213\n",
      "Epoch:3/19\ttrain Loss: 1.1395 Acc: 0.4912 Time: 6.6370\tval Loss: 1.1880 Acc: 0.4079 Time: 1.3807\n",
      "Epoch:4/19\ttrain Loss: 0.7728 Acc: 0.6814 Time: 5.6783\tval Loss: 1.4561 Acc: 0.4737 Time: 1.0201\n",
      "Epoch:5/19\ttrain Loss: 1.0161 Acc: 0.5796 Time: 5.9035\tval Loss: 1.1554 Acc: 0.4605 Time: 1.1718\n",
      "Epoch:6/19\ttrain Loss: 0.9507 Acc: 0.5664 Time: 5.7675\tval Loss: 1.0966 Acc: 0.3947 Time: 1.1881\n",
      "Epoch:7/19\ttrain Loss: 0.9336 Acc: 0.5575 Time: 5.8301\tval Loss: 1.0749 Acc: 0.4737 Time: 1.1669\n",
      "Epoch:8/19\ttrain Loss: 0.6391 Acc: 0.6947 Time: 5.9123\tval Loss: 1.2671 Acc: 0.5132 Time: 1.1531\n",
      "Epoch:9/19\ttrain Loss: 0.4706 Acc: 0.8319 Time: 5.7660\tval Loss: 2.2014 Acc: 0.5263 Time: 1.1601\n",
      "Epoch:10/19\ttrain Loss: 0.6129 Acc: 0.7611 Time: 6.0645\tval Loss: 2.0248 Acc: 0.5263 Time: 1.2299\n",
      "Epoch:11/19\ttrain Loss: 0.4541 Acc: 0.7876 Time: 6.4339\tval Loss: 1.6753 Acc: 0.5000 Time: 1.2288\n",
      "Epoch:12/19\ttrain Loss: 0.3262 Acc: 0.8938 Time: 6.9017\tval Loss: 1.6069 Acc: 0.6053 Time: 1.3716\n",
      "Epoch:13/19\ttrain Loss: 0.3080 Acc: 0.8717 Time: 7.0133\tval Loss: 1.9936 Acc: 0.5263 Time: 1.1914\n",
      "Epoch:14/19\ttrain Loss: 0.2308 Acc: 0.9071 Time: 6.4670\tval Loss: 2.0032 Acc: 0.5921 Time: 1.2114\n",
      "Epoch:15/19\ttrain Loss: 0.2189 Acc: 0.9115 Time: 5.9022\tval Loss: 2.4664 Acc: 0.5658 Time: 1.3752\n",
      "Epoch:16/19\ttrain Loss: 0.1643 Acc: 0.9513 Time: 6.6404\tval Loss: 3.2763 Acc: 0.5263 Time: 1.3029\n",
      "Epoch:17/19\ttrain Loss: 0.1249 Acc: 0.9425 Time: 5.6535\tval Loss: 3.8817 Acc: 0.5526 Time: 1.0945\n",
      "Epoch:18/19\ttrain Loss: 0.1138 Acc: 0.9558 Time: 6.2417\tval Loss: 4.1533 Acc: 0.5658 Time: 1.2991\n",
      "Epoch:19/19\ttrain Loss: 0.1381 Acc: 0.9513 Time: 5.9792\tval Loss: 3.7268 Acc: 0.5921 Time: 1.1831\n",
      "\n",
      "Training complete in 2m 31s\n",
      "Best val acc: 0.6053\n",
      "On Test:\tLoss: 2.1556 Acc: 0.5263\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    # 訓練データ\n",
    "    # 水増し（左右反転、45度回転）を行う\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # バリデーションデータ\n",
    "    # 通常はFlip等は行わない。\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    # テストデータ\n",
    "    # 通常はFlip等は行わない。\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((WIDTH, HEIGHT)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 以下は、水増し前と同じ。\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "lr = 0.03\n",
    "momentum = 0.9\n",
    "outdir = \".\"\n",
    "\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "\n",
    "# 損失関数、最適化方法、学習率の更新方法を定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "\n",
    "# 深層学習の実行\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=epochs)\n",
    "# テストデータでの精度を求める\n",
    "print_test_accuracy(model, criterion, optimizer, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本質的に画像の枚数が不十分であることもあり、十分な精度向上は見込めませんが、手順として、このようなことが行われるということを認識して頂ければと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 積み残しの課題\n",
    "\n",
    "何点か、このテキストで積み残している課題です。\n",
    "1. ResNet等頻繁に利用されているモデルの利用。\n",
    "2. それらを用いた転移学習。\n",
    "3. 核以外の染色画像の利用\n",
    "\n",
    "学習に関して本質的に対処が必要な問題として\n",
    "1. 画像の枚数の確保\n",
    "2. 今回は顕微鏡画像から切り出した酵母の細胞画像を利用しているが、同一視野の画像は類似の傾向があると考えられるので、その補正（テスト画像選択時に、同一視野の画像を全て除くなど）\n",
    "\n",
    "などがあります。学習時に意図しないバイアスは頻繁に入りうるので、注意をする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
